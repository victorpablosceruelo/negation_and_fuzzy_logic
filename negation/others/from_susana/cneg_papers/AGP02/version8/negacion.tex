%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% NEGATION. PADL'00
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\documentclass[]{llncs}
\newcommand{\tab}{\hspace{2em}}
\newcommand{\N}{I\!\!N}


%% TITULO %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{How to Incorporate Negation \\ in a Prolog Compiler}

\author{Juan Jos\'{e} Moreno-Navarro, Susana Mu\~noz-Hern\'andez}

\institute{Universidad Polit\'{e}cnica de Madrid
    \thanks{Dpto.\ LSIIS - Facultad de Inform\'{a}tica. 
                Campus de Montegancedo s/n,
            28660, Madrid, SPAIN.  %%\hspace{2cm}~~%% OJO!!
                email:\texttt{jjmoreno@fi.upm.es}, 
                      \texttt{susana@lml.ls.fi.upm.es},
        voice: +34-91-336-7458, fax: +34-91-336-7412. This
                research was partly supported by the Spanish CICYT project 
                TIC96.1012-C02-02.
    }
}


\linespread{0.9}
\newlength{\zero}
\setlength{\zero}{0pt}
\renewcommand{\topsep}{\zero}
\renewcommand{\abovedisplayskip}{\zero}
\renewcommand{\belowdisplayskip}{\zero}
\renewcommand{\abovedisplayshortskip}{\zero}
\renewcommand{\belowdisplayshortskip}{\zero}



\newenvironment{mytabbing}
   {\vspace{0.3em}\begin{small}\begin{tabbing}}
   {\end{tabbing}\end{small}\vspace{0.3em}}



\begin{document}
\pagestyle{empty}

\maketitle

%% ABSTRACT %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
  Knowledge representation based applications require a more complete
  set of capabilities than those offered by conventional Prolog
  compilers. Negation is, probably, the most important one.  The
  inclusion of negation among the logical facilities of LP has been a
  very active area of research, and several techniques have been
  proposed. However, the negation capabilities accepted by current
  Prolog compilers are very limited.  In this paper, we discuss the
  possibility to incorporate some of these techniques in a Prolog
  compiler in an efficient way. Our idea is to mix some of the
  existing proposals guided by the information provided by a global
  analysis of the source code.

\noindent
{\bf Keywords:} Semantics of Negation, Global Analysis, Implementation of Negation.
\end{abstract}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\partopsep -0.6em

%\pagestyle{plain}
%\setcounter{page}{1}

%%%%%%%%%%%%%%%%%%% INTRODUCTION %%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

Knowledge representation based applications are a natural area for
logic programming. However, this kind of applications requires a more
complete set of capabilities than those offered by conventional Prolog
compilers. As the knowledge about any subject contains positive as
well as negative information, the possibility to include negation in
goals is crucial for knowledge representation.

For these reasons, the research community on negation in LP has made a
lot of efforts to propose different ways to understand and incorporate
negation into logic programming languages. Most of the interesting
proposals rely on semantics, and a considerable amount of papers in
logic programming conferences is devoted to these subjects.
Surprisingly, only a small subset of these ideas has arrived to the
field on implementation and has produced modifications to Prolog
compilers. In fact, the negation capabilities incorporated by current
Prolog compilers are rather limited. To our knowledge, the only
negation techniques that are present in a (commercial) Prolog compiler
are: 

%%\vspace{-8pt}

\begin{itemize}
%%\addtolength{\topsep}{-8pt}
\item The (unsound) negation as failure rule, that is present in most
  Prolog compilers (Sicstus, Bin Prolog, Quintus, etc.).
\item The sound (but incomplete) delay technique of the language
  G\"odel \cite{Goedel}, or Nu-Prolog \cite{Naish} which applies
  negation as failure when the variables of the negated goal are
  ground. It is well known that it has the risk of floundering.
\item The constructive negation of Eclipse, which was announced in
  earlier versions but has been removed from recent releases.
\end{itemize}
%\vspace{-8pt}

There are some direct approaches to implement negation (as the implementation of
 stable models or bottom-up computation style like XSB). However
our goal is to  study the possibility to go a bit further
than these experiences, and to design the steps needed to extend a
Prolog compiler with a negation subsystem. Notice that this allows us
to keep the very advanced Prolog current implementations based on
the WAM technology as well as to reuse thousands of Prolog code lines.

Our work does not try to propose any new method, but to combine
existing techniques to make some negation techniques useful for
practical application. The novelty appears in some implementation
oriented improvements of existing techniques, the uniform
presentation, and, mainly, in the techniques used for the combination
and the combination strategy.

We are interested in techniques with a single and simple semantics.
For this reasons we adopt the most simple possibility: Closed Word
Assumption (CWA) \cite{Clark} by program completion and Kunen's
3-valued semantics \cite{Kunen}. These semantics will be the basis for
soundness results.

Therefore, the techniques we are interested in need to share these
semantics. Another important issue is that they must be
``constructive'', i.e. the program execution need to search for the
values that make false a negated goal. One can argue that Chan's
constructive negation \cite{Chan1,Chan2} fulfills both points, but it
is quite difficult to implement and expensive in terms of execution
resources.  Therefore, our idea is to try to use the simplest
technique as possible in any particular case. To help on this
distinction, we need to use some tests to characterize the situation.
To avoid the execution of these tests during the execution of the
program, the results of a global analysis of the source code are used.
The program analyses includes groundness detection, elimination of
delays, and the determination of the finiteness of the number of
solutions.

All these analyses are incorporated in the CIAO development system
\cite{ciao-novascience}, an extension of Sicstus Prolog, which
will be used as the testbed for our implementation work.

Our goal is to write a paper more expositive than technical, although
some details about the techniques used and the soundness of the method
are provided.

The rest of the paper is organized as follows. Section 2 presents some
preliminaries: we discuss the negation techniques to be used, and
briefly enumerate the characteristics of the program analyses. In
order to present how the techniques can be introduced in a Prolog
compiler, we start with the management of disequality constraints
(Section 3), then we discuss the implementation of (a part of)
constructive negation (Section 4).  Intensional negation as well as
the computation of universal quantified goals are studied in Section
5.  Section 6 explains how to combine all the techniques and Section 7
shows some experimental results. Finally, we conclude.


%%%%%%%%%%%%%%%%%% TREATMENT OF NEGATION %%%%%%%%%%%%%%%%%%%%%%

\vspace{-7pt}
\section{Preliminaries}
\vspace{-7pt}
In this section we introduce some previous work on negation
and program analysis that will be used along the paper.

\subsection{Treatment of Negation}

Among the techniques that have been proposed to implement the
computation of negated goals of the form $\neg Q$ in a program $P$
based on the CWA, the most accepted are the following:

%\vspace{-8pt}
\begin{itemize}
%%\addtolength{\itemsep}{-8pt}
\item The negation as finite failure rule of Clark \cite{Clark}, which
  states that $\neg Q$ is a consequence of a program P if a finitely
  failed SLD tree for the query $Q$ with respect to P exists, (in
  short, if $Q$ finitely fails). The implementation provided by Prolog
  compilers is the following:

%\vspace{-10pt}
\begin{tt}
\begin{mytabbing}
~~~~\= naf (Q) :- Q, !, fail. \\
    \> naf (Q).
\end{mytabbing}
\end{tt}
%\vspace{-10pt}

\noindent
that is unsound except when the free variables of $Q$ are not 
constrained (for instance, if  $Q$ has
no free variables).

\item There are many works related to the program completion of
Clark \cite{Clark}, (see \cite{Lloyd,Apt}), some of them
(\cite{Barbuti1,Barbuti2}) oriented to obtain a program
that is a transformation of a original program $P$ which
introduces also the ``only if'' part of the predicate
definitions (i.e., interpreting implications as equivalences).


\item The constructive negation proposed by Chan
\cite{Chan1,Chan2}, and formalized in the context of CLP
by Stuckey \cite{Stuckey}.
\end{itemize}


%%%%%%%%% INFORMATION OBTAINED BY GLOBAL ANALYSIS %%%%%%%%%%%%

\subsection{Information obtained by global analysis}
In order to provide some heuristics to guide the computation
of the negation process we will use some information provided
by a global analysis of the source program.
Along the paper we assume that a part of the Prolog compiler
produces with an acceptable level of accuracy, the following information.
At least this is true for the CIAO system:

%\vspace{-8pt}
\begin{itemize}
%\addtolength{\itemsep}{-8pt}
\item Groundness: The groundness analysis tries to identify those
variables that are bound to a ground term in a certain point
of the program. There are several papers and implementation of
groundness analysis (see \cite{GroundnessCIAO}).

\item Elimination of delays: In the presence of delays (or waits)
the analysis tries to identify which of them are useless (so,
removing them), or if there is a reordering of the goals that
does not need the delay directive (see \cite{DelayCIAO,Puebla}).

\item Finiteness of the number of solutions: The analysis is based
on complexity and execution cost to determine if a goal has a
finite number of solutions (even none) or there are a potential
infinite number of answers. The interested reader can consult
\cite{Lopez2,Braem}.
\end{itemize}

%%%%%%%%%%%%% MANAGEMENT OF DISEQUALITY CONSTRAINTS %%%%%%%%%%%%%

\vspace{-7pt}
\section{Management of disequality constraints}
\vspace{-7pt}

The first step in our management of negation is to handle
disequalities between terms $t_1 \neq t_2$. Most
Prolog implementations can work with disequalities if
both terms are ground (built-in predicate {\tt /==}).
However, they cannot work in the
presence of free variables. The ``constructive'' behavior
must allow the ``binding'' of a variable with a disequality:
the solution to the goal {\tt X /== t}
is the constraint $X \neq t$. In fact, what we need is
an implementation of CLP (${\cal H}$) (constraints over the Herbrand
Universe with equality and disequality). This capability is
present in several CLP Prolog extensions (Prolog III for instance),
but is not available in usual Prolog compilers. As we are
going to prove, the inclusion of disequalities and constrained
answers has a very low cost.

First of all, we need a representation for constraint answers. The
disequation $c (X, a) \neq c (b, Y)$ introduces a disjunction
$X \neq b \vee Y \neq a$. For this reason, we use conjunctions of
disjunctions of disequations as normal forms.  On the other
hand, we will produce disequations by means of the negation of
an equation $X = t (\overline{Y})$. This fact produces the
universal quantification of the free variables in the equation,
unless a more external quantification affects them. The
negation of such equation is $\forall~ \overline{Y}~X \neq t(\overline{Y})$.
Also, universally quantified disequations are allowed in
the constraints. More precisely, the normal form of
constraints is:

%\vspace{-20pt}
\[ \underbrace{\bigwedge_i (X_i = t_i)}_{\mbox{positive information}} \wedge
\underbrace{\bigvee_j \forall~ \overline{Z}_j^1~(Y_j^1 \neq s_j^1)
\wedge \ldots \wedge \bigvee_l \forall~ \overline{Z_l}^n~(Y_l^n
\neq s_l^n)}_{\mbox{negative information}} \]
%\vspace{-20pt}

\noindent
where each $X_i$ appears only in $X_i = t_i$, none $s_k^r$ is $Y_k^r$
and the universal quantification could be
empty (leaving a simple disequality).

Using some normalization rules we can obtain a normal form
formula from any initial formula. It is easy to redefine
the unification algorithm to manage constrained variables.

This very compact way to represent a normal form was firstly presented in
\cite{Moreno1} and differs from Chan's representation where
only disjunctions are used\footnote{Chan treats the disjunctions
by means of backtracking. The main advantage of our normal form is
that the search space is drastically reduced.}.

Therefore, in order to include disequalities into a Prolog compiler we
need to reprogram unification. It is possible if the Prolog version
allows attributed variables \cite{Carlsson} (e.g. in Sicstus Prolog,
or in Eclipse where they are called meta-structures). These
variables let us keep associated information with each variable during
the unification what can be used to dynamically control the
constraints.

Attributed variables are variables with an associated attribute,
which is a term. We will associate to each variable a data structure
containing a normal form constraint. Basically, a list of list of
pairs (variable, term) is used. They behave like ordinary
variables, except that the programmer can supply code for
unification, printing facilities and memory management.
In our case, the printing facility is used to show constrained
answers. The main task is to provide a new unification code.

Once the unification of a variable $X$ with a term $t$ is
triggered, there are three possible cases (up to
commutativity):

%\vspace{-5pt}
\begin{enumerate}
%\addtolength{\itemsep}{-8pt}
\item if $X$ is a free variable and $t$ is not a variable with a negative
constraint, $X$ is just bind to $t$,
\item if $X$ is a free variable or bound to a term $t'$ and
$t$ is a variable $Y$ with a negative constraint, we need to check
if $X$ (or, equivalently, $t'$) satisfies the constraint associated with $Y$.
A conveniently defined predicate {\tt satisfy} is used for this purpose.
\item if $X$ is bound to a term $t'$ and $t$ is a term (or a variable
bound to a term), the classical unification algorithm can be used.
\end{enumerate}
%\vspace{-5pt}

The predicate {\tt =/=}, to check disequalities, is defined in
a similar way than unification. The main difference is that it
incorporates negative constraints instead of bindings and the
decomposition step can produce disjunctions.

As an example, let us show the constraints produced in certain
situations. The attribute/ constraint of a variable is
represented as a list of list of pairs (variable, term) using
a constructor {\tt /}, i.e. the disequality $X \neq 1$ is
represented as {\tt X / 1}.
When an universal quantification is used in a disequality
(e.g. $\forall Y~ X \neq c (Y)$) the new constructor
{\tt fA}$/2$ is used (the previous constraint is represented
as {\tt fA (Y, X =/= c (Y))}.
The first list is used to represent disjunctions while
the inside list represents the conjunction of disequalities.
We focus on the variable $X$.

%\hspace{-0.5cm}
\begin{center}
\begin{small}
\begin{tabular}{lll}
SUBGOAL & ATTRIBUTE & CONSTRAINT \\
\hline\hline
\ \\
{\tt not\_member (X,[1,2,3])} &  $[[X/1,X/2,X/3]]$ &
                  $X \neq 1 \wedge X \neq 2 \wedge X \neq 3$\\
%{\tt member (X,[1,2,3]), X=/=2} &  $[[X/1,X/3]]$ &
%                  $X \neq 1 \wedge X \neq 3$\\
{\tt member (X,[1]), X=/=1} &  {\tt fail} & $false$ \\
{\tt X =/= 4} & $[[X/4]]$ & $X \neq 4$ \\
{\tt X =/= 4; X=/=5}  & $[[X/4], [X/5]]$ & $X \neq 4 \vee X \neq 5$ \\
{\tt X =/= 5; (X=/=6, X=/=Y)}  & $[[X/4],[X/6, X/Y]]$ &
$X \neq 4 \vee (X \neq 6 \wedge X \neq Y)$\\
{\tt member (X,[0,s(0),s(s(0))]),} & & \\
{\tt fA (Y, X =/= s (Y))} & $0$ & $X = 0$
\end{tabular}
\end{small}
\end{center}

%%%%%%%%%%%%%%%%%%%%% CONSTRUCTIVE NEGATION %%%%%%%%%%%%%%%%%%%%%%

\vspace{-7pt}
\section{Constructive negation}
\vspace{-7pt}

% Hablar del caso sencillo.
The second technique we are going to implement is constructive
negation. Constructive negation was proposed by Chan
\cite{Chan1,Chan2} and it is widely accepted as the
``most promising'' method to handle negation with Kunen's 3-valued
semantics
(up to some extensions and modifications proposed by other authors).
Although the first Chan's paper is credited as the presentation
of the idea, but a ``mistake'' in the development of the technique
(solved in the second one), it has still some interesting results
from the implementation point of view. The main idea of constructive
negation is easy to describe: in order to obtain the solutions
for $\neg Q$ we proceed as follows:

%\vspace{-8pt}
\begin{enumerate}
%\addtolength{\itemsep}{-8pt}
\item Firstly, the solutions for $Q$ are obtained getting a
disjunction: $ Q \equiv S_1 \vee S_2 \vee ... \vee S_n $. Each
component $S_i$ can be understood as a conjunction of equalities: $
S_i \equiv S_i^1 \wedge S_i^2 \wedge \ldots \wedge S_i^{m_i} $

\item Then the formula is negated and a normal
form constraint is obtained:
%\vspace{-8pt}

\begin{center}
\begin{tabular}{lll}
$\neg Q \equiv$
  & $\neg (S_1 \vee S_2 \vee \ldots \vee S_n)$ & $\equiv$ \\
  & $\neg S_1 \wedge \neg S_2 \wedge \ldots \wedge \neg S_n$ & $\equiv$ \\
  & $\neg (S_1^1 \wedge \ldots \wedge S_1^{m_1}) \wedge \ldots \wedge
    \neg (S_n^1 \wedge \ldots \wedge S_n^{m_n})$ & $\equiv$ \\
  & $(\neg S_1^1 \vee \ldots \vee \neg S_1^{m_1}) \wedge \ldots \wedge
    (\neg S_n^1 \vee \ldots \vee \neg S_n^{m_n})$ & \\
%    (S_{11} \wedge S_{21} \wedge ...
%S_{n1}) \vee ...  \vee (S_{1i1} \wedge S_{2i2} \wedge ...
%S_{nin}) \vee  ...  \vee (S_{1m1} \wedge S_{2m2} \wedge ...
%S_{nmn}) \]
\end{tabular}
%\vspace{-8pt}
\end{center}

The formula can be obtained in different ways depending on how
we negate a solution. It can also be arranged into a disjunction
of conjunctions according to the variables in each $S_i^j$.
\end{enumerate}
%\vspace{-8pt}

Of course, the solution is not valid in general, because a goal ($Q$
in the previous description) can have an infinite number of solutions.
\cite{Chan1} offers a technique to negate a solution and to normalize
the previous formula.  \cite{Moreno1}, working on a CLP framework as
proposed by \cite{Stuckey}, adapted the idea (in a different but
equivalent context) using our notion of constraint normal form.  Given
a constraint \\[-2ex]
%
%\vspace{-5pt}
%
\begin{displaymath}
  \bigwedge_{i=1}^m (X_i = t_i) \wedge
   \bigwedge_{j=1}^n \bigvee_{k=1}^{n_j}\forall~
   \overline{Z}_k^j~ (Y_k^j \neq s_k^j)
\end{displaymath}
%
%\vspace{-5pt}
%
%\noindent
the negation will produce the following constraints:

%\vspace{-8pt}
\begin{itemize}
%%\addtolength{\itemsep}{-8pt}
\item $\bigvee_{i=1}^m \forall~\overline{Z}_i~ (X_i \neq t_i)$, where
$\overline{Z}_i$ are the variables of $t_i$ not quantified outside.


\item $\bigwedge_{i=1}^m (X_i = t_i) \wedge
       \bigwedge_{k=1}^{n_l} (Y_l^k = s_l^k) ~\wedge~
       \bigwedge_{j=1}^{l-1} \bigvee_{k=1}^{n_j}
       \forall~ \overline{Z}_k^j~
       (Y_k^j \neq s_k^j)$, for all $l \leq n$.

\end{itemize}
%\vspace{-5pt}

Note, again, that we are using a much more compact representation
for the negated constraints than that proposed in \cite{Chan1}.

Once we have explained how to negate a constraint, the rest is
easy: for each solution, each possibility of the negation is
combined with one of the others. All these different solutions
are obtained by backtracking.

We implement $\neg Q$ by the Prolog predicate {\tt cneg (Q)}, and it works
as follows:
%\vspace{-8pt}
\begin{enumerate}
%%\addtolength{\itemsep}{-8pt}
\item First of all, all variables $V$ of the goal $Q$ are obtained.
\item Secondly, all $Q$'s solutions for variables in $V$
are computed using {\tt setof}$/3$. Each solution is a constraint in
normal form.
\item The negation of each solution is computed and
combined to obtain the answers of $\neg Q$ one by one.
\end{enumerate}
This implementation is only valid when it is detected that
the goal has a finite number of solutions.
The full code (\cite{Susana}) is available from the authors on request.

Some examples were the technique is useful are the following.
They are extracted from a running session.

\begin{small}
\begin{tt}
\hspace{-0.5cm}
\begin{minipage}[h]{7.8cm}
\begin{mytabbing}
\=$|$ ?- \= cneg (X =/= Y). \\
    \>       \> X = Y \\
    \>$|$ ?- \> cneg (X=/=Y, member(Y,[1,2])). \\
    \>       \> Y /= 1, Y /= 2 ?;\\
    \>       \> X = 1, Y = 1 ?; \\
    \>       \> X = 2, Y = 2  \\
    \>$|$ ?- \> cneg(member(Y,[X]),member(Y,[2])). \\
    \>       \> X /= 2; Y /= 2
\end{mytabbing}
\end{minipage}
\begin{minipage}[h]{7.8cm}
\begin{mytabbing}
\=$|$ ?- \= cneg (X =/= X). \\
    \>       \> true\\
    \>$|$ ?- \> cneg (cneg (X =/= X)). \\
    \>       \> no \\
    \>$|$ ?- \> cneg(member(X,[1,2,3])). \\
    \>       \> X /= 1, X /= 2, X /= 3 \\
    \>$|$ ?- \> cneg ([1,X] =/= [Y,2]). \\
    \>       \> Y = 1, X = 2
\end{mytabbing}
\end{minipage}
\end{tt}
\end{small}

%%%%% INTENSIONAL NEGATION AND UNIVERSAL QUANTIFICATION %%%%%%%%%

\vspace{-7pt}
\section{Intensional negation and universal quantification}
\vspace{-7pt}

Intensional negation \cite{Barbuti1,Barbuti2}
uses a different approach to handle negation.
A program transformation technique is used to add new predicates
to the program in order to express the negative information.
Informally, the {\em complement} of head terms of the positive
clauses are computed and they are used later as the head of the
negated predicate.

For example, the transformation of a program (from \cite{Barbuti1}):
%\vspace{-5pt}
\begin{tt}
\begin{mytabbing}
~~~~\= even (0). \\
    \> even (s(s(X))) :- even (X).
\end{mytabbing}
\end{tt}
%\vspace{-5pt}
yields a new predicate {\tt not\_\_even}
that succeeds when {\tt even} fails.

%\vspace{-5pt}
\begin{tt}
\begin{mytabbing}
~~~~\= not\_\_even (s(0)). \\
    \> not\_\_even (s(s(X))) :- not\_\_even (X).
\end{mytabbing}
\end{tt}
%\vspace{-5pt}

There are two problems with this technique. The first one is
that in the presence of logical variables in the rhs of
a clause, the new program needs to handle some kind of universal
quantification construct. The second trouble affects the outcomes of
the program: while the
new program is semantically equivalent to the completed program,
the operational behavior can differ. In the presence of
logical variables, the new predicate can generate all the
possible values one by one, even when a more general answer
can be given. The predicate $P$ defined by the single
clause $p(X, X).$ is negated by:

%\vspace{-5pt}
%\begin{tt}
%\begin{mytabbing}
%~~~~\= p (X, X). 
%\end{mytabbing}
%\end{tt}
%\vspace{-5pt}

%\noindent
%is negated by:
%\vspace{-5pt}
\begin{tt}
\begin{mytabbing}
~~~~\= not\_\_p (X, Y) :- not\_\_eq (X, Y). \\
    \> not\_\_eq (0, s(Y)). \\
    \> not\_\_eq (s(X), 0). \\
    \> not\_\_eq (s(X), s(Y)) :- not\_\_eq (X, Y).
\end{mytabbing}
\end{tt}
%\vspace{-15pt}
\noindent
if the program only contains natural numbers with {\tt 0} and {\tt succ}.
The query \linebreak
{\tt not\_\_p (X,Y)} will generate infinitely many answers,
instead of the more general $X \neq Y$. An answer like $X \neq Y$ can only be re

placed by an infinite number of equalities.

Our approach to manage this problem is to use constraints
instead of concrete terms. All what we need is to have disequality
constraints, which are included yet. Therefore, the
negated predicates of the previous examples, with our transformation,
are the following:

%\vspace{-5pt}
\begin{tt}
\begin{mytabbing}
~~~~\=not\_\_even (X) :- X =/= 0, fA (Y, X =/= s(s(Y))). \\
    \>not\_\_even (s(s(X))) :- not\_\_even (X). \\
    \> not\_\_p (X, Y) :- X =/= Y.
\end{mytabbing}
\end{tt}
%\vspace{-5pt}

Note that if the program only contains natural numbers,
the first clause is equivalent to the one obtained above.

A bit more complicate is the first problem.
For this purpose we have implemented a predicate
{\tt for\_all}$/4$ that tries to detect if a goal $Q$ is
valid for all possible values of a list of variables
$[X_1, \ldots, X_n]$ with a call to the goal \linebreak
{\tt for\_all ([X1, ..., Xn], Q, \ldots)}.

Roughly speaking, the implementation, explained
in more detail later, generates incrementally all possible
instantiations of the variables
$X_1, \ldots, X_n$ by terms $t_1(\overline{Y}), \ldots, t_n(\overline{Y})$
and tries to make true the goal $Q$, for all these possibilities, 
without instantiating the variables $\overline{Y}$ at all. The idea was ske
tched in \cite{Barbuti2} but
many important details where ignored and no concrete implementation
was supplied.

\subsection{Program transformation}

Our transformation approach basically follows the ideas of 
\cite{Barbuti2}, but
differs in some significant points. Barbuti and his coauthors 
apply the transformation to a
restricted class of programs. Then they show that any program
can be translated into a program of that class. However, while
both programs are semantically equivalent, they are not operationally
equivalent (infinitely many answers can appear as shown above). 
Our transformation 
applies to all kind of programs and maintains compact outcomes.

In order to formally define the negated predicate {\tt not\_\_p}
for {\tt p} we proceed step by step. First of all we need the
definition of the complement of a term $t$. Without using constraints,
the only way to represent the complement of a term is a set of terms.
However, this set can be expressed by means of a constraint on a
variable $X$ that does not appear in the term (i.e. the constrained
values for $X$ are exactly the terms that have not $t$'s shape).
\bigskip

\noindent
{\bf Definition:} {\em Complement of a term}

\noindent
The complement of a term $t$ (not using the variable $X$)
on the variable $X$ (in symbols $Comp (t)$) is a constraint
value for $X$, defined inductively as follows:
%\vspace{-5pt}
\begin{itemize}
%\addtolength{\itemsep}{-8pt}
\item $Comp (Y) = fail$
\item $Comp (c) = (X \neq c)$, with $c$  constant.
\item $Comp (c (t_1, \ldots, t_n)) =
         \forall~ \overline{Z} (X \neq c (t_1, \ldots, t_n))$,
         with $c$ a constructor and $\overline{Z}$ the variables
         of $t_1, \ldots, t_n$.
\end{itemize}
%\vspace{-5pt}

Without loss of generality we can consider that all the predicates
has one argument, taking the tuple construction as a
constructor. Given a set of clauses for a predicate $p$:

%\vspace{-15pt}
\begin{mytabbing}
~~~~\=C$_1$: $p (t^1)$ \=$:-$ \=$G_1 $. \\
    \>~~~\ldots \\
    \>C$_m$: $p (t^m)$ \>$:-$\> $G_m $. 
\end{mytabbing}
%\vspace{-12pt}

\noindent
we say that the {\bf complement clause} of $p$ is

%\vspace{-5pt}
\begin{mytabbing}
~~~~\=$not\_\_p (X) ~:- ~Comp (t^1), \ldots, Comp (t^m)$. \\
\end{mytabbing}
%\vspace{-15pt}

%\begin{displaymath}
%  not\_\_p (X) ~:- ~Comp (t^1), \ldots, Comp (t^m).
%\end{displaymath}

\noindent
assuming, by adequate renamings, that the terms do not share variables
(i.e. $var (t^i) \cap var (t^j) = \emptyset$ for $i \neq j$).

This clause covers the cases where there is no definition for the
predicate in the original program,
and it must be included in the new program.
For the rest of the clauses of the negated predicates some additional
concepts are needed:

\medskip
%\bigskip
\noindent
{\bf Definition:} {\em Critical pair}

\noindent
We say that a program has a critical pair $t$ in
$\{l_1, \ldots, l_r\} \subseteq \{1, \ldots, m\}$ if
%\vspace{-5pt}
$m.g.u. (t^{l_1}, \ldots, t^{l_r}) = \sigma \mbox{ and }
t = t^{l_j}\sigma, ~~~\forall~ j \in \{1, \ldots,r\}$
%\vspace{-15pt}


\smallskip
The definition is well know in term rewriting and, intuitively,
detects those terms for which there are more than one 
applicable clause. In those cases, all the $rhs$s of the applicable
clauses must be negated together.

For each critical pair $t$ of the
program in $\{l_1, \ldots, l_r\}$ we generate the following clause:

%\vspace{-5pt}
\begin{mytabbing}
~~~~\=$not\_\_p (t) ~:-
           ~negate\_rhs (var (t), (G_{l_1}; \ldots; G_{l_r})).$ 
\end{mytabbing}
%\vspace{-15pt}

\noindent
where the $negate\_rhs$ function negates a clause rhs (see below).
There is no rule if all the $G_{l_j}$ are empty.
Note that the formula
$p (t) \longleftrightarrow \exists \overline{X} G_{l_1} \vee \ldots \vee G_{l_r}
$ ($\overline{X} = var(G_{l_1} \cup \ldots \cup var(G_{l_r})$) is
part of the completed program.

Now, we are in a position to transform each of the clauses of
the program. Each clause $p (t^i) :- ~G_i$.
%\vspace{-5pt}
%\begin{mytabbing}
%~~~~\=$p (t^i) :- G_i$.
%\end{mytabbing}
%\vspace{-5pt}
%\noindent
generates one of the following clauses for $not\_\_p$:

%\vspace{-5pt}
\begin{itemize}
%\addtolength{\itemsep}{-8pt}
\item \begin{mytabbing}
$not\_\_p (t^i) :- t^i =/= t, negate\_rhs (var (t^i), G_i)$.
\end{mytabbing}

\noindent
if there is a critical pair $t$ involving clause $i$ and $t^i$ is not
strictly identical to t ($t^i /==t$).

\item \begin{mytabbing}
$not\_\_p (t) :- negate\_rhs (var (t^i), G_i)$.
\end{mytabbing}

\noindent
otherwise. There is no clause if $G_i$ is empty.
\end{itemize}

The effect of $negate\_rhs$ is easy to explain. It just
negates the rhs and introduces universal quantifications when
they are needed:

%\vspace{-10pt}
\begin{tabular}{lll}
$\bullet$ &  $negate\_rhs (V, G) = negate (G)$ & if $var (G) \subset V$\\
$\bullet$ &  $negate\_rhs (V, G) =
            {\tt for\_all} ([Y_1, \ldots, Y_k], negate (G))$ &  if $var
            (G) - V =$\\
& & $ ~~~~\{Y_1, \ldots, Y_k\} \neq \emptyset$.   
\end{tabular}
%\vspace{-5pt}

The function $negate$ can be defined inductively: it moves conjunction
({\tt ,}) into disjunction ({\tt ;}), equality into disequalities and vice versa

.

The effect of
$negate$ over a single predicate call needs a further discussion.
In principle it is possible to define $negate (q (s))$ by any of
the methods to handle negation: negation as failure
({\tt naf (q (s))}), constructive negation ({\tt cneg (q (s))}) or
the transformed predicate ({\tt not\_\_q (s)}). The last one
will be used in case of recursive calls. The decision will
be fixed by the negation strategy of the compiler that will
be discussed in the next section.

The transformation has some similarities with the transformation
proposed in \cite{Bruscoli}, but there are still 
some differences. The transformation
of \cite{Bruscoli} has a much more simple formulation and some
optimization covered by our detection of critical pairs are
not taken into account. The result is that much more universally
quantified goals are generated and the programs contains a lot
of trivial constraints (i.e. they are trivially true or false,
as $X = a ~\wedge~ X \neq a$, $X = a ~\vee~ X \neq a$).

Let us discuss the application of the method in a couple of
examples. Consider the fragment of the program:

%\vspace{-5pt}
\begin{tt}
\begin{mytabbing}
~~~~\=less (0, s(Y)). \\
    \>less (s(X), s(Y)) :- less (X, Y).
\end{mytabbing}
\end{tt}
%\vspace{-5pt}

First of all, we need to compute the complements of the terms in
the lhs of the clauses, with respect to the variable pair
$(W, Z)$. We have: 
\begin{itemize}
\item $Comp (0, s (Y)) = (W \neq 0, \forall~ Y (Z \neq s (Y)))$
\item $Comp (s (X), s (Y)) = (\forall~ X (W \neq s (X)),
                              \forall~ Y (Z \neq s (Y)))$
\end{itemize}
%
%\begin{eqnarray*}
% Comp (0, s (Y)) & = & (W \neq 0, \forall~ Y (Z \neq s (Y))) \\
% Comp (s (X), s (Y)) & = & (\forall~ X (W \neq s (X)),
% \forall~ Y (Z \neq s (Y)))   
%\end{eqnarray*}
The complement clause is:
%\vspace{-5pt}
\begin{tt}
\begin{mytabbing}
~~~~\=not\_\_less (W, Z) :- \= W =/= 0,   \\
    \>                      \>  fA (X, W =/= s (X)), \\
    \>                      \>  fA (Y, Z =/= s (Y)). 
\end{mytabbing}
\end{tt}
%\vspace{-5pt}
\noindent
There are no critical pairs and the first clause has no rhs, so the
transformed clause is:

%\vspace{-5pt}
\begin{tt}
\begin{mytabbing}
~~~~\=not\_\_less (s (X), s (Y)) :- not\_\_less (X, Y).
\end{mytabbing}
\end{tt}
%\vspace{-5pt}

\noindent
The second example, {\em family}, is also well known, and includes free
variables in the rhs:

%\vspace{-5pt}
\begin{tt}
\begin{mytabbing}
~~~~\=parent (john, mary). ~~~~\= ancestor (X, Y) :- parent (X, Y).\\
    \>parent (john, peter). \> ancestor (X, Y) :- \= ancestor (X, Z),\\ 
    \>parent (mary, joe).   \>                    \> parent (Z, Y). \\
    \>parent (peter, susan). 
\end{mytabbing}
\end{tt}
%\vspace{-5pt}
\noindent
The transformation of the predicate {\tt ancestor} has no complement
clause. The first and the second clause have an obvious critical
pair $(X, Y)$. The associated clause is:

%\vspace{-5pt}
\begin{tt}
\begin{mytabbing}
~~~~\=not\_\_ancestor (X, Y) :- \= cneg (parent (X,Y)), \\
    \>                          \> for\_all ([Z],
                       \=(not\_\_ancestor (X, Z); \\
    \>                          \>  \>~cneg (parent (Z,Y))).
\end{mytabbing}
\end{tt}
%\vspace{-5pt}

Note that we have used {\tt cneg} as the way to negate the
predicate {\tt parent}. It is safe because {\tt parent}
has always a finite number of solutions. In the case we can
infer that a call to $\neg parent (Z, Y)$ is ground, we can use
{\tt naf} instead of {\tt cneg}. Also, the call inside
the {\tt for\_all} goal has the first argument ground for sure.

In principle, we need to transform each of the clauses of the
predicate, including
the constraint $(X, Y) \neq (X, Y)$ in their bodies, but it
is trivially unsatisfiable and we can omit the clauses.


%%%%%%%%%%%%%%% UNIVERSAL QUANTIFICATION %%%%%%%%%%%%%%%%%%


%\vspace{-10pt}
\subsection{Implementation of universal quantification}
%\vspace{-8pt}
The efficient implementation of universally quantified goals is not an
easy task. In fact it is an undecidable problem. However,
we are not interested in a complete implementation but a
implementation powerful enough to resolve the quantifications that we
obtain from the previous transformation. There are other approaches to
implement some kind of universal quantification:
%\vspace{-5pt}
\begin{enumerate}
%\addtolength{\itemsep}{-8pt}
\item Nu-Prolog \cite{Naish} and G\"{o}del \cite{Goedel} include
universally quantified goals, but they are executed when
all the variables are ground. Obviously it has the risk of
floundering.
\item Voronkov \cite{Voronkov} has studied
the use of bounded quantifications over finite sets.
\end{enumerate}

\noindent
But both are rather limited. Our implementation is based on two ideas:
%\vspace{-5pt}
\begin{enumerate}
%\addtolength{\itemsep}{-8pt}
\item A universal quantification of the goal $Q$ over a
variable $X$ succeeds when $Q$ succeeds without
binding (or constraining) $X$.
\item A universal quantification of $Q$ over $X$ is true
if $Q$ is true for all possible values for the variable $X$.
\end{enumerate}

The second point can be combined with the first one
in order to get an implementation. Instead of generating
all possible values (which is not possible in the presence
of a constructor of arity greater than 0) we can generate
all the possible skeletons of values, using new
variables. The simplest possibility is to include all the
constants and all the constructors applied to fresh
variables. Now, the universal quantification is tested for
all this terms, using the new variables in the
quantification.

In order to formalize this concept, we need the notion of
{\bf covering}.

%\bigskip
\smallskip
\noindent
{\bf Definition:} {\em Covering of the Herbrand Universe}
\noindent
A covering is any set of terms $\{t_1, \ldots, t_n\}$ such
that:
%\vspace{-5pt}
\begin{itemize}
%\addtolength{\itemsep}{-8pt}
\item For every $i, j$ with $i \neq j$, $t_i$ and $t_j$ do
not superpose, i.e. there is no ground substitution $\sigma$
with $t_i\sigma = t_j\sigma$.
\item For all ground term $s$ of the Herbrand Universe there
exists $i$ and a ground substitution $\sigma$ with
$s = t_i\sigma$.
\end{itemize}
The simplest covering is a variable $\{X\}$. If the program
uses only natural numbers, the following sets of terms are
coverings:
%\vspace{-5pt}
\begin{itemize}
%\addtolength{\itemsep}{-8pt}
\item $\{0, s (X)\}$
\item $\{0, s (0), s(s(X))\}$
\item $\{0, s (0), s(s(0)), s(s(s(X)))\}$
\end{itemize}

The example also gives us the hint about how to
incrementally generate coverings. We depart from the simplest
covering $X$. From one covering we generate the next one
choosing one term and one variable of this term. The term is
removed and then we add all the terms obtained replacing the
variable by all the possible instances of that element.

In order to fix a strategy to select the term and the variable
we use a Cantor's diagonalization\footnote{This is the method
to enumerate $\N^m$. It ensures that all elements are visited in
a finite number of steps.} to explore the domain of a
set of variables. It is a breadth first strategy to cover
every element of the domain. The previous concepts extend
trivially in the case of tuple of elements of the
Herbrand Universe, i.e. several variables.

We implement the universal quantification by means of the
predicate \linebreak
{\tt for\_all ([X1,\ldots,Xn], Q,D,S)}, where $X1,\ldots,Xn$ are the
universal quantified variables, $Q$ is the goal or predicate, $D$ is
the depth until we want to generate coverings, and $S$ is an output
parameter indicating the success of the evaluation. We start with the
initial covering $\{(X_1,\ldots,X_n)\}$ of depth 1.

The current covering is checked with the predicate $Q$. This
means that for each element $\overline{t}$ in the covering
we execute $Q$ replacing the variables $(X_1, \ldots, X_n)$ by
$\overline{t}$. We have three possibilities:
%\vspace{-5pt}
\begin{enumerate}
%\addtolength{\itemsep}{-8pt}
\item $Q$ succeeds in all the cases without any bind of the
variables introduced by the covering, then the universal
quantification is true.
\item $Q$ fails for a ground case, then the universal quantification
is false for sure.
\item $Q$ fails in at least one of the cases. The next covering
is generated and the process continues recursively.
\end{enumerate}

There are two important details that optimize the execution.
The first one is that in order to check if there are bindings
in the covering variables, it is better to replace them by
new constants that do not appear in the program. In other words,
we are using ``Skolem constants''.

The second optimization is much more useful. Notice that the
coverings grow up incrementally, so we only need to check the
most recently included terms. The other ones have been checked
before and there is no reason to do it again.

As an example, consider a program which uses only natural
numbers: the sequence of coverings for the
goal $\forall~ X,Y,Z ~ p(X,Y,Z)$ will be the following
 (where {\tt Sk (i)}, with $i$ a number, represents the ith
Skolem constant).
%\vspace{-3pt}
\begin{small}
\begin{mytabbing}
$C_1 = [(Sk(1),Sk(2),Sk(3))]$ \\
$C_2 = [\underline{(0,Sk(1),Sk(2))}, \underline{(s(Sk(1)),Sk(2),Sk(3))}]$ \\
$C_3 = [\underline{(0,0,Sk(1))}, \underline{(0,s(Sk(1)),Sk(2))},
        (s(Sk(1)),Sk(2),Sk(3))]$ \\
$C_4 = [\underline{(0,0,0)}, \underline{(0,0,s(Sk(1)))},
        (0,s(Sk(1)),Sk(2)),(s(Sk(1)),Sk(2),Sk(3))]$ \\
$C_5 = [(0,0,0), \underline{(0,0,s(0))}, \underline{(0,0,s(s(Sk(1))))},
        (0,s(Sk(1)),Sk(2)),$ \\
~~~~~~~~$        (s(Sk(1)),Sk(2),Sk(3))]$\\
$C_6 = \ldots$
\end{mytabbing}
\end{small}
%\vspace{-3pt}

In each step, only two elements need to be checked, those that appear
underlined. The rest are part of the previous covering and they
do not need to be checked again. Again, the authors can supply
details of the code (or see \cite{Susana}).

Let us show some examples of the use of the {\tt for\_all} predicate,
indicating the covering found to get the solution. We are still
working only with natural numbers and we are going to consider a
maximal depth of 5:

%\vspace{-8pt}
\begin{tt}
\begin{mytabbing}
~~~~\=$|$ ?- \=for\_all ([X], even (X), 5, S). \\
    \>       \>S = fail 
\end{mytabbing}
\end{tt}
%\vspace{-8pt}

\noindent
with the covering of depth 3 $\{0, \underline{s (0)}, s(s(Sk(1))\}$.

%\vspace{-8pt}
\begin{tt}
\begin{mytabbing}
~~~~\=$|$ ?- \= for\_all ([X], X =/ a, 5, S). \\
    \>       \> S = true
\end{mytabbing}
\end{tt}
%\vspace{-8pt}

\noindent
with the covering of depth 1 $\{Sk (1)\}$.

%\vspace{-8pt}
\begin{tt}
\begin{mytabbing}
~~~~\=$|$ ?- \=for\_all ([X], less (0, X) -$>$ less (X, Y), 5, S). \\
    \>       \>Y = s (s(\_A)), S = true 
\end{mytabbing}
\end{tt}
%\vspace{-8pt}

\noindent
with the covering of depth 2 $\{0, s (Sk (1))\}$.
\bigskip


The general solution does not guarantee completeness of the
query evaluation process. There are some cases when the generation
of coverings does not find one which is correct or incorrect. Nevertheless,
this solution fails to work properly in very particular cases.
Remember that we are not interested in giving the user an universal
quantification operator, but just to implement the code coming
from the transformation of a negated predicate. In order to have 
a practical use of the method, we limite the depth of the coverings
to some (user defined) constant $d$. If the {\em for\_all/4} predicate is 
not able to achieve a solution at this depth, the predicate informs that
it is not possible to know the result of the computation at that depth
$d$ ({\tt S = unknown}).

%\vspace{-5pt}
\subsection{Behaviour of the application of the technique}
%\vspace{-5pt}
Here we have some examples coming from a running session that
show the behaviour of the transformation technique:

\begin{small}
\begin{tt}
\begin{minipage}[h]{10cm}
\begin{mytabbing}
\=$|$?- \=not\_\_even (s(s(0))). \\
    \>      \>no \\
\>$|$?- not\_\_even (s(s(s(0)))). \\
    \>      \>yes \\
\>$|$?- not\_\_even(X). \\
    \>      \>X =/= 0,fA(\_A,X=/=s(s(\_A))) ?;\\
    \>      \>X=s(s(Y)),Y=/=0,fA(\_A,Y=/=s(s(\_A))) ?; \\
    \>      \> \vdots \\
\>$|$?- not\_\_less (0, s(X)). \\
    \>      \>no \\
\>$|$?- not\_\_less (s(X), 0). \\
    \>      \>true 
\end{mytabbing}
\end{minipage}
\begin{minipage}[h]{7.3cm}
\begin{mytabbing}
\=$|$?- \=not\_\_less(s(X),X). \\
    \>      \>unknown \\
\>$|$?- not\_\_ancestor(mary,peter).\\
    \>      \>yes \\
\>$|$?- not\_\_ancestor(john,X). \\
    \>      \>no \\
\>$|$?- not\_\_ancestor(peter,X). \\
    \>      \>X = john ? ; \\
    \>      \>X = mary ? ; \\
    \>      \>X = joe ? ; \\
    \>      \>X = peter 
\end{mytabbing}
\end{minipage}
\end{tt}
\end{small}

\smallskip
The divergence of the goal {\tt not\_\_less(s(X), X)} is of the
same nature of the divergence of {\tt less (X, s (X))} and is
related to the incompleteness of Prolog implementations.

In any case, our implementation provides only sound results, although
there are cases where we cannot provide any result.



%%%%%%%%%%%%%% THE COMPILER STRATEGY %%%%%%%%%%%%%%%%%%%%%%%

\vspace{-7pt}
\section{The compiler strategy}
\vspace{-7pt}
Once we have described the main implemented methods,
we can discuss the most important part: the combination of
these techniques in order to get a system to handle negation.

What we need is a strategy that the compiler can use to generate code
for a negated goal. The strategy is fixed by the information of the
different program analyses.  Notice that the strategy also ensures the
soundness of the method: if the analysis is correct, the precondition
to apply a technique is ensured, so the results are sound.  Given a
(sub)goal of the form $\neg G (\overline{X})$ the compiler produces
one of the following codes:

%\vspace{-5pt}
\begin{enumerate}
%\addtolength{\itemsep}{-8pt}
\item If the analysis of the program ensures that $G (\overline{X})$
is ground then simple negation as failure is applied, i.e. it
is compiled to {\tt naf} ($G (\overline{X})$). Since floundering is
undecidable, the analysis only provides an approximation of the cases
where negation as failure can be applied safely. This means that
maybe we are avoiding to use the technique even in cases that it
could work properly.

\item Otherwise, the compiler generates a new program
replacing the goal by $G (\overline{X})$ and adding a delay
directive to get ground variables in $\overline{X}$ before the call.
Then, the compiler applies the elimination of delays technique.
If the analysis and the program transformation are able to remove
the delay (maybe moving the goal), use the outcoming program but
replace $G (\overline{X})$ by {\tt naf} ($G (\overline{X})$)
as before. Again, the approximation of the analysis could forbid
us to apply constructive negation in cases it should give a sound
result.

\item Otherwise, look for the result of the finiteness analysis.
If it ensures that $G (\overline{X})$
has a finite number of solutions, then the compiler can use simple
constructive negation, transforming the negated goal into
{\tt cneg} ($G (\overline{X}))$.

\item Otherwise, the compiler uses the intensional negation approach.
Some negated predicates are generated and the goal is replaced by
$negate (G (\overline{X}))$.

During this process new negated goal can appear and the same
compiler strategy is applied to each of them.

\item If the intensional negation cannot compute a result, full
constructive negation is used.
\end{enumerate}

The weakest point of this strategy appears in the last two steps. The
decision to use intensional negation or full constructive negation is
dynamic. We are trying to statically identify when the universal
quantification can be used (this is related with the {\em negation as
  instantiation} property of \cite{nai}).  On the other hand, we have
not yet an implementation of full constructive negation.

The strategy is complete and sound with respect to Kunen 3-valued semantics, wha
t is deduced from the soundness
of the negation techniques, the correctness of the analysis and the
completeness of constructive negation. This result is obtained as a 
straightforward composition of the corresponding soundness and correctness
theorems.

Let us conclude showing a small example.  The static analysis studies
each negated goal in the input program and the strategy applies the
simplest technique in each case.

\bigskip

\noindent
\begin{small}
%\begin{tt}
\begin{minipage}[h]{0.5\textwidth}
%\centerline{SOURCE PROGRAM}
SOURCE PROGRAM \smallskip
%\hrule
\begin{tt}
\begin{mytabbing}
\= p(X):- \=member(X,[0,s(0),s(s(0))]), \\
  \>       \> $\neg$ less(X,s(s(0))).\\
  \\
  \> q(X):-\>$\neg$ less(X,s(s(0))),\\
  \>       \>member(X,[0,s(0),s(s(0))]).\\
  \\           
  \> r(X):-\>$\neg$ less(X,s(s(0))).\\
  \\
  \> t(X):-\>$\neg$ less(s(0),Y).
\end{mytabbing}
\end{tt}
\end{minipage}
\begin{minipage}[h]{0.5\textwidth}
%\centerline{TRANSFORMED PROGRAM}
TRANSFORMED PROGRAM \smallskip
%\hrule
\begin{tt}
\begin{mytabbing}
\= p(X):- \=member(X,[0,s(0),s(s(0))]), \\
 \>       \>naf(less(X,s(s(0)))). \\
 \\
 \>    q(X):-\>member(X,[0,s(0),s(s(0))]), \\
 \>          \>naf(less(X,s(s(0)))). \\
 \\
 \>    r(X):-\>cneg(less(X,s(s(0)))). \\
 \\
 \>    t(X):-\>not\_\_less(s(0),Y).
\end{mytabbing}
\end{tt}
\end{minipage}
%\end{tt}
\end{small}

\subsection{Experimental Results}

Up to now, we have applied this strategy manually (using the real
results of the analyzers) and a good collection of programs (found 
in the literature about negation) has been checked. They are
small and medium size examples, but this is the usual kind of problems
where negation is applied.
As a future work, we plan to modify
the CIAO compiler in order to implement our strategy.
To report the results, we have selected a small number of 
examples to show how our strategy works.
A summary of the techniques that our compiler chooses to solve
each negation goal appears in the following table where we use the short
names: naf (negation as failure), delay (elimination of delays
technique), cneg (simple constructive negation), and intneg
(intensional negation). 
\medskip
\begin{center}
%\begin{small}
\begin{tabular}{lll}
EXAMPLE & NEGATION USED & REFERENCE \\
\hline
\hline
free                        & cneg   & \cite{Stark}    \\
ordered                     & cneg/naf   & \cite{Chan2}    \\
different digits ~\hspace{0.8cm}            & delay       & \cite{Chan2}    \\
greater                     & intneg      & \cite{Barbuti1} \\
family                      & intneg/cneg ~\hspace{1.8cm}~& \cite{Lloyd}    \\
disconnected                & intneg & \cite{VGelder}  \\
\end{tabular}
%\end{small}
\end{center}
\medskip
{\em free} constructs natural numbers and checks if they do not belong
to a given list. {\em ordered} deduces if a list is sorted by checking
if there are not
two consecutive unsorted elements. {\em different digits} detects if a list
contains only different numbers (if there are not duplicates). {\em greater}
is implemented as the negation of less or equal. {\em family} is the example
presented in section 5 (with {\em parent/2} and {\em ancestor/2}). {\em disconne
cted} indicates that two vertices of
a graph are disconnected if one of them is not reachable from the other.

\vspace{-7pt}
\section{Conclusion}
\vspace{-7pt}

Prolog can be more widely used for knowledge representation based applications
if negated goals can be included in programs.
We have presented a collection of techniques, more or less well
known in logic programming, that can be used together in order
to produce a system that can handle negation efficiently.
Although we do not claim to invent any ``new method'' to
implement negation, to our knowledge it is one of the first
serious attempts to include such proposals on the incorporation of
negation into a Prolog compiler.

Our main contribution is the use of the information of a program
analyzer to define a strategy to organize the use of the
negation components. The strategy is designed
to be a good trade-off between complexity and generality.

Some other contributions of the paper are the management of
disequality constraints using attributed variables and the new
compact way to handle constraint normal forms, which has a number of
advantages.

The transformation approach in term of disequality
constraint is another important point, because it solves some
of the problems of intensional negation \cite{Barbuti2} 
in a more efficient way than \cite{Bruscoli}.

Finally, the approach to compute universally quantified goals
was sketched in \cite{Barbuti2}, but the concrete implementation
needs to solve a lot of technical difficulties, what makes our
implementation more than a student exercise.

The results of the practical experimentation are quite acceptable
on time (although some of the involved algorithms are exponential). 
We can provide a table of runtime on request. 
However, we have not
included them because of the lack of space and, mainly, because
they are not significative due to the fact that we cannot compare with 
other existing implementations; they do not exist.

As a future work, we plan to modify the compiler in order to
produce a version of CIAO with negation. 
It will give us a
real measure of what important is the information of the
analyzer to help our strategy. On the other hand, there are
still some unsolved problems. The most important is the
detection of the cases where the universal quantification does
not work in order to avoid the overhead of the {\tt for\_all} 
predicate when it
cannot find a solution. Of course, we will need to use
full constructive negation, hard to implement and, probably, not
very efficient. The work of \cite{Drabent} could help on this task.
In any case, it will be the last resource to be used and will ensure the 
completeness of the method.

%\vspace{-10pt}



%%%%%%%%%%%%%%%%%%%% BIBLIOGRAPHY %%%%%%%%%%%%%%%%%%%%%
\begin{small}
%\vspace{-10pt}

\bibliographystyle{plain}
\bibliography{bibliografia}

\end{small}

\end{document}










