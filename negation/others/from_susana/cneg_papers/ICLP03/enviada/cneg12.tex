%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Implementation of Constructive Negation for Prolog 
% (con el ingles corregido)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{llncs}

%% \newenvironment{mytabbing}
%%    {\vspace{0.3em}\begin{small}\begin{tabbing}}
%%    {\end{tabbing}\end{small}\vspace{0.3em}}

%%\newenvironment{mytabbing}
%%   {\begin{tabbing}}
%%   {\end{tabbing}}

\usepackage{pst-node}

\usepackage{amsmath} %% for functions defined using different parts
\usepackage{amssymb}
\usepackage{latexsym}
\usepackage{times}
\usepackage{mathptmx}
\usepackage{theorem}


\newcommand{\naf}{{\em naf}}\newcommand{\viejo}[1]{}
\newcommand{\ciao}{Ciao}


\newcommand{\tab}{\hspace{2em}}
\newcommand{\ra}{$\rightarrow~$}
\newcommand{\Ra}{\Rightarrow~}
\newcommand{\HINT}{{\cal H\!-\!INT}}
%\newcommand{\cts}{\mid}
\newcommand{\cts}{~[\!]~}
\newcommand{\N}{I\!\!N}

\newcommand{\ToDo}[1]{
  \begin{center}
      \begin{minipage}{0.75\textwidth}
        \hrule
        \textbf{To do:}\\
        {\em #1}
        \hrule
      \end{minipage}\\
  \end{center}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{A Real Implementation for \\
       Constructive Negation}

%\author{~~Susana Mu\~{n}oz~~~~~~~~~ Juan Jos\'{e} Moreno-Navarro \\
%         \email{susana@fi.upm.es}~~~~~~~~~~ \email{jjmoreno@fi.upm.es}}
\author{~~~~~~~~~~~~ Susana Mu\~{n}oz ~~~~ Juan Jos\'{e} Moreno-Navarro \\
 \email{susana@fi.upm.es}~~~~~ \email{jjmoreno@fi.upm.es}}

\institute{ 
LSIIS, Facultad de Inform\'{a}tica \\
Universidad Polit\'{e}cnica de  Madrid \\ 
Campus de Montegancedo s/n Boadilla del Monte\\
28660 Madrid, Spain \footnote{This work was partly supported by the
Spanish MCYT project TIC2000-1632.} \\
 }

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-12pt}

%



\begin{abstract}
  Logic Programming has been advocated as a language for system
  specification, especially for those involving logical behaviours,
  rules and knowledge. However, modelling problems involving negation,
  which is quite natural in many cases, is somewhat limitated if
  Prolog is used as the specification / implementation language. These
  restrictions are not related to theory viewpoint, where users can
  find many different models with their respective semantics; they
  concern practical implementation issues.  The negation capabilities
  supported by current Prolog systems are rather limited, and there is
  no correct and complete implementation.  In this paper, we refine
  and propose some extensions to the method of constructive negation,
  providing the complete theoretical algorithm. Furthermore, we also
  discuss implementation issues providing a preliminary
  implementation.
\end{abstract}

\paragraph{\bf Keywords}
Constructive Negation, Negation in Logic Programming, Constraint Logic
Programming, Implementations of Logic Programming.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%% INTRODUCTION %%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{introduction}
From its very beginning Logic Programming has been advocated to be
both a programming language and a specification language. It is
natural to use Logic Programming for specifying/programming systems
involving logical behaviours, rules and knowledge. However, this idea
has a severe limitation: the use of negation. Negation is probably the
most significant aspect of logic that was not included from the
outset. This is due to the fact that dealing with negation involves
significant additional complexity. Nevertheless, the use of negation
is very natural and plays an important role in many cases, for
instance, constraints management in databases, program composition,
manipulation and transformation, default reasoning, natural language
processing, etc.

% Work done in negation
Although this restriction cannot be perceived from the theoretical point of
view (because there are many alternative ways to understand and
incorporate negation into Logic Programming), the problems really start
at the semantic level, where the different proposals (negation as
failure (\naf), stable models, well-founded semantics, explicit
negation, etc.)  differ not only as to expressiveness but also as to
semantics.  However, the negation techniques supported by current
Prolog compilers are rather limited, restricted to negation as failure
under Fitting/Kunen semantics \cite{Kunen} (sound only under some
circumstances usually not checked by compilers) which is a built-in or
library in most Prolog compilers (Quintus, SICStus, Ciao, BinProlog,
etc.), and the ``delay technique'' (applying negation as failure only
\emph{when} the variables of the negated goal become ground, which is
sound but incomplete due to the possibility of floundering), which is
present in Nu-Prolog, G\"odel, and Prolog systems that implement
delays (most of the above).

Of all the proposals, constructive negation \cite{Chan1,Chan2} is
probably the most promising because it has been proven to be sound and
complete, and its semantics is fully compatible with
Prolog's. Constructive negation was, in fact, announced in early
versions of the Eclipse Prolog compiler, but was removed from the
latest releases.  The reasons seem to be related to some technical
problems with the use of coroutining (risk of floundering) and the
management of constrained solutions.


The goal of this paper is to give an algorithmic description of
constructive negation, i.e. explicitly stating the details needed for
an implementation. We also intend to discuss the pragmatic ideas
needed to provide a concrete and real implementation. Early results
for a concrete implementation extending the \ciao\ Prolog compiler are
presented.  We assume some familiarity with constructive negation
techniques and Chan's papers.

The remainder of the paper is organized as follows. Section
\ref{constructive} details our constructive negation algorithm. It
explains how to obtain the $frontier$ of a goal (Section
\ref{frontier}), how to prepare the goal for negation (Section
\ref{preparation}) and, finally, how to negate the goal (Section
\ref{negation}). Section \ref{implementation} discusses implementation
issues: code expansion (Section \ref{expansion}), required disequality
constraints (Section \ref{disequality}), optimizations (Section
\ref{optimization}), examples (Section \ref{examples}) and some
experimental results (Section \ref{results}).  Finally, we conclude
and outline some future work.
 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%   CONSTRUCTIVE NEGATION   %%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Constructive Negation}
\label{constructive}

Most of the papers addressing constructive negation deal with semantic
aspects. In fact, only the original papers by Chan gave some hints
about a possible implementation based on coroutining, but the
technique was only outlined. When we tried to reconstruct this
implementation we came across several problems, including the
management of constrained answers and floundering (which appears to be
the main reason why constructive negation was removed from recent
versions of Eclipse). It is our befief that this problems cannot be
easily and efficiently overcome. Therefore, we decided to design an
implementation from scratch.  One of our additional requirements is
that we want to use a standard Prolog implementation (to be able to
reuse thousands of existing Prolog lines and maintain their
efficiency), so we will avoid implementation-level manipulations. This
is coherent with the usual Prolog definition of \naf:

\begin{verbatim}
naf (P):- P, !, fail.
naf (P).
\end{verbatim}

We start with the definition of a frontier and how it can be managed
to negate the respective formula.

%%%%%%%%% FRONTIER  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Frontier}
\label{frontier}

Firstly, we present Chan's definition of frontier (we actually owe the formal
definition to Stuckey \cite{Stuckey95}).

\begin{definition}{\em Frontier}

A frontier of a goal $G$ is the disjunction of a finite set of nodes
in the derivation tree such that every derivation of $G$ is either
finitely failed or passes through exactly one {\em frontier node}.
\end{definition}

What is missing is a method to generate the frontier. So far we have
used the simplest possible frontier: the frontier of depth 1 obtained
by taking all the possible single SLD resolution steps. This can be
done by a simple inspection of the clauses of the
program\footnote{Nevertheless, we plan to improve the process by using
abstract interpretation and detecting the degree of evaluation of a
term that the execution will generate.}.  Additionally, built-in based
goals receive a special treatment (moving conjunctions into
disjunctions, disjunctions into conjunction, eliminating double
negations, etc.)

\begin{definition}{\em Depth-one frontier}

    \begin{itemize} 

\item If $G \equiv (G_1;G_2) $ then $Frontier(G) \equiv$
$Frontier(G_1) \vee Frontier(G_2)$.

\item If $G \equiv (G_1,G_2) $ then $Frontier(G) \equiv$
  $Frontier(G_1) \wedge Frontier(G_2)$ and then we have to apply
  DeMorgan's distributive property to retain the disjunction
  of conjunctions format.
  
\item If $G \equiv p( \overline{X}) $ and 
  predicate $p/m$ is defined by N clauses:

$
~~~~~~~~~~p( \overline{X}^1):- C_1'. \\
~~~~~~~~~~p( \overline{X}^2):- C_2'. \\
~~~~~~~~~~\ldots \\
~~~~~~~~~~p( \overline{X}^3):- C_N'. \\
$

The frontier of the goal has the format: $Frontier(G) \equiv \{C_1
\vee C_2 \vee \ldots \vee C_N\}$, where each $C_i$ is the union of the
conjunction of subgoals $C_i'$ plus the equalities that are needed to
unify the variables of $\overline{X}$ and the respective terms of
$\overline{X}^i$.

    \end{itemize}

\end{definition}

\noindent
Consider, for instance, the following code:

\begin{verbatim}
odd(s(0)).
odd(s(s(X))) :- odd(X).
\end{verbatim}

The frontier for the goal $odd (Y)$ is as follows:

\[Frontier(odd(Y)) = \{ ( Y=s(0) ) \vee ( Y=s(s(X)) \wedge odd(X) ) \} \] 

To get the negation of $G$ it suffices to negate the frontier
formula. This is done by negating each component of the disjunction of
all implied clauses (that form the frontier) and combining the
results.


The solutions of $cneg(G)$ are the solutions of the combination
(conjunction) of one solution of each of the N conjunctions
$C_i$. Now we are going to explain how to negate a single
conjunction $C_i$. This is done in two phases: \emph{Preparation} and
\emph{Negation of the formula}.



%%%%%%%% PREPARATION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Preparation}
\label{preparation}

% Comparar con Chan

Before negating a conjunction obtained from the frontier, we have to
simplify, organize, and normalize this conjunction:

\begin{itemize}

\item {\bf Simplification of the conjunction}. If one of the terms of
$C_i$ is trivially equivalent to $true$ (e.g. $X=X$), we can eliminate
this term from $C_i$. Symmetrically,if one of the terms is trivially
$fail$ing (e.g. $X \neq X$), we can simplify $C_i \equiv fail$. The
simplification phase can be carried out during the generation of
frontier terms.

\item {\bf Organization of the conjunction}. Three groups are created containing the components of $C_i$, which are divided into equalities ($\overline{I}$), 
disequalities ($\overline{D}$), and other subgoals ($\overline{R}$). 
Then, we get $C_i \equiv \overline{I}
\wedge \overline{D} \wedge \overline{R}$.
  
\item {\bf Normalization of the conjunction}. Let us classify the
variables in the formula. The set of variables of the
goal is called $GoalVars$. The set of free variables of $\overline{R}$
is called $RelVars$.

    \begin{itemize}


       \item {\bf Elimination of redundant variables and
       equalities}. If $I_i \equiv X = Y$, where $Y \not\in GoalVars$,
       then we now have the formula $ ( I_1 \wedge \ldots \wedge
       I_{i-1} \wedge I_{i+1} \wedge \ldots \wedge I_{NI} \wedge
       \overline{D} \wedge \overline{R}~) \sigma $, where $ \sigma = \{
       Y / X \}$, i.e. the variable $Y$ is substituted by $X$ in the
       entire formula. 
       \item {\bf Elimination of irrelevant disequalities}. $ImpVars$
       is the set of variables of $GoalVars$ and the variables that
       appear in $\overline{I}$. The disequalities $D_i$ that contain
       any variable that was neither in $ImpVars$ nor in $RelVars$ are
       irrelevant and should be eliminated.

    \end{itemize}

 \end{itemize}

 

%%%%%%%% NEGATION OF THE FORMULA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Negation of the formula}
\label{negation}

It is not feasible, to get all solutions of $C_i$ and to negate their
disjunction because $C_i$ can have an infinite number of solutions. So,
we have to use the general constructive negation algorithm.

We consider that $ExpVars$ is the set of variables of $\overline{R}$
that are not in $ImpVars$, i.e. $RelVars$, except the variables of
$\overline{I}$ in the normalized formula.
\medskip

\noindent
{\em First step: {\bf Division of the formula}}

\noindent
$C_i$ is divided into:

\[C_i \equiv \overline{I} \wedge
        \overline{D}_{imp} \wedge \overline{R}_{imp} \wedge
        \overline{D}_{exp} \wedge \overline{R}_{exp} \]

\noindent
where $\overline{D}_{exp}$ are the disequalities in $\overline{D}$
with variables in $ExpVars$ and $\overline{D}_{imp}$ are the other
disequalities, $\overline{R}_{exp}$ are the goals of $\overline{R}$
with variables in $ExpVars$ and $\overline{R}_{imp}$ are the other
goals, and $\overline{I}$ are the equalities.

Therefore, the constructive negation of the divided formula is: \\

$~~~~~~~~~~~~~~~~~~~~\neg~C_i \equiv \neg~\overline{I} \vee $ \\
$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(\overline{I} \wedge \neg~\overline{D}_{imp}) \vee  $ \\
$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(\overline{I} \wedge \overline{D}_{imp}  \wedge \neg~\overline{R}_{imp}) \vee $ \\
$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~( \overline{I} \wedge \overline{D}_{imp} \wedge \overline{R}_{imp} \wedge \neg~(\overline{D}_{exp} \wedge \overline{R}_{exp})) $ \\

\noindent
It is not possible to separate $\overline{D}_{exp}$ and
$\overline{R}_{exp}$ because they contain free variables and
they cannot be negated separately. The answers of the negations
will be the answers of the negation of the equalities, the answers of
the negation of the disequalities without free variables, the answers
of the negation of the subgoals without free variables and the answers
of the negation of the other subgoals of the conjunctions (the ones
with free variables). Each of them will be obtained as follows:
\medskip

\noindent
{\em Second step: {\bf Negation of subformulas}}

        \begin{itemize}

           \item {\bf Negation of $\overline{I}$}. We have $\overline{I}
           \equiv I_1 \wedge \ldots \wedge I_{NI} \equiv$ \[ \exists~
           \overline{Z}_1~ X_1 = t_1 \wedge \ldots \wedge \exists~
           \overline{Z}_{NI}~ X_{NI} = t_{NI} \] where
           $\overline{Z}_i$ are the variables of the equality $I_i$ that
           are not included in $GoalVars$ (i.e. that are not quantified
           and are therefore free variables). When we negate this
           conjunction of equalities we get the constraint 
                \[
           \underbrace{\forall~ \overline{Z}_1~ X_1 \neq t_1} _{\neg~
           I_1} \vee \ldots \vee \underbrace{\forall~
           \overline{Z}_{NI}~ X_{NI} \neq t_{NI} } _{\neg~ I_{NI}}
           \equiv %\] 
%                \[ 
           \bigvee_{i=1}^{NI} \forall~ \overline{Z}_i X_i
           \neq t_i \] 
           This constraint is the first answer of the
           negation of $C_i$ that contains $NI$ components.

           \item {\bf Negation of $\overline{D}_{imp}$}. If we have
           $N_{D_{imp}}$ disequalities $\overline{D}_{imp} \equiv D_1
           \wedge \ldots \wedge D_{N_{D_{imp}}}$ where $ D_i \equiv
           \forall~ \exists~ \overline{Z}_i ~\overline{W}_i ~  Y_i
           \neq s_i$ where $Y_i$ is a variable of $ImpVars$, $s_i$ is
           a term without variables in $ExpVars$, $\overline{W}_i$ are
           universally quantified variables that are neither in the
           equalities \footnote{There are, of course, no universally
           quantified variables in an equality}, nor in the other
           goals of $\overline{R}$ because otherwise $\overline{R}$
           would be a disequality of $\overline{D}_{exp}$. Then we
           will get $N_{D_{imp}}$ new solutions with the format: \\

           $\overline{I} \wedge \neg~ D_1 $ \\ 
           $\overline{I} \wedge
           D_1 \wedge \neg~ D_2 $ \\ 
           $\ldots $ \\ 
           $\overline{I} \wedge
           D_1 \wedge \ldots \wedge D_{N_{D_{imp}}-1} \wedge \neg~
           D_{N_{D_{imp}}}$ \\ 

           where $ \neg~ D_i \equiv \exists~
           \overline{W}_i~ Y_i = s_i$. The negation of a universal
           quantification turns into an existential quantification and
           the quantification of free variables of $\overline{Z}_i$
           gets lost, because the variables are unified with the evaluation of
           the equalities of $\overline{I}$. Then, we will get
           $N_{D_{imp}}$ new answers.


           \item {\bf Negation of $\overline{R}_{imp}$}. If we have
           $N_{R_{imp}}$ subgoals $\overline{R}_{imp} \equiv R_1
           \wedge \ldots \wedge R_{N_{R_{imp}}}$. Then we will get
           new answers from each of the conjunctions: \\

           $\overline{I} \wedge \overline{D}_{imp} \wedge \neg~ R_1 $ \\ 
           $\overline{I} \wedge \overline{D}_{imp} \wedge
           R_1 \wedge \neg~ R_2 $ \\ 
           $\ldots $ \\ 
           $\overline{I} \wedge \overline{D}_{imp} \wedge
           R_1 \wedge \ldots \wedge R_{N_{R_{imp}}-1} \wedge \neg~
           R_{N_{R_{imp}}}$ \\ 

           where $ \neg~ R_i \equiv cneg(R_i)$. Constructive negation
           is again applied over $R_i$ recursively using this
           operational semantics.


           \item {\bf Negation of $\overline{D}_{exp} \wedge
           \overline{R}_{exp}$}. This conjunction cannot be disclosed
           because of the negation of $ \exists~ \overline{V}_{exp}~
           \overline{D}_{exp} \wedge \overline{R}_{exp}$, where
           $\overline{V}_{exp}$ gives universal quantifications:\\
           $\forall~ \overline{V}_{exp}~ cneg(\overline{D}_{exp}
           \wedge \overline{R}_{exp})$. The entire constructive
           negation algorithm must be applied again. Note that the new
           set $GoalVars$ is the former set $ImpVars$. Variables of
           $\overline{V}_{exp}$ are considered as free variables. When
           solutions of $cneg(\overline{D}_{exp} \wedge
           \overline{R}_{exp})$ are obtained some can be rejected:
           solutions with equalities with variables in
           $\overline{V}_{exp}$. If there is a disequality with any of
           these variables, e.g. $V$, the variable will be universally
           quantified in the disequality.  This is the way to negate
           the negation of a goal, but there is a detail that was not
           considered in former approaches and that is necessary to
           get a sound implementation: the existence of universally
           quantified variables in $\overline{D}_{exp} \wedge
           \overline{R}_{exp}$ by the iterative application of the
           method.  So, what we are really negating is a subgoal of
           the form: $ \exists~ \overline{V}_{exp}~ \overline{D}_{exp}
           \wedge \overline{R}_{exp}$.  Here we will provide the last
           group of answers that come from:

           \[\overline{I} \wedge \overline{D}_{imp}
           \wedge \overline{R}_{imp} \wedge \forall~
           \overline{V}_{exp}~ \neg~(\overline{D}_{exp} \wedge
           \overline{R}_{exp})\]

         \end{itemize}


    

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%  IMPLEMENTATION ISSUES  %%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Implementation Issues}
\label{implementation}

Having described the theoretical algorithm, including important
details, we now discuss important aspects for a practical
implementation, including how to compute the frontier and manage
answer constraints.

%%%%%%%% CODE EXPANSION  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Code Expansion}
\label{expansion}

The first issue is how to get the frontier of a goal. For this
purpose, the code of the predicates involved needs to be available
during execution to construct the frontier. It is possible to handle
the code of clauses during the execution thanks to the Ciao package
system \cite{ciao-modules-cl2000}, which allows the code to be
expanded at run time.  Therefore, we have been able to evaluate and
execute predicates and also provide their code to calculate their
$Frontiers$ at any step of the algorithm. The expansion is implemented
in the $cneg.pl$ package which is included in the declaration of
the module that is going to be expanded (i.e. where there are goals
that are negations).

A simple example would be the module $mod1.pl$ that exports the
predicate $odd/1$ and the predicate $not\_odd/1$ that, semantically, is
the negation of $odd/1$:
\begin{verbatim}
:- module(mod1,[odd/1,not_odd/1],[cneg]).

odd(s(0)).
odd(s(s(X))) :- odd(X).

not_odd(X) :- cneg(odd(X)).
\end{verbatim}
The loading of the $cneg.pl$ package means that the compiler works
with an expanded code added to the previous code:
\begin{verbatim}
stored_clause(odd(s(0)),[]).
stored_clause(odd(s(s(X))),[odd(X)]).
\end{verbatim}
where information about code structure is stored to be used by the
negation algorithm. Now, the execution is able to compute the frontier
we described above $\{ ( Y=s(0) ) \vee ( Y=s(s(X)) \wedge odd(X) ) \}$

Note that a similar, but less efficient, behaviour can be emulated
using metaprogramming facilities, available in most Prolog compilers.
 

%%%%%%%% DISEQUALITY CONSTRAINTS  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Disequality constraints}
\label{disequality}

An instrumental step for managing negation is to be able to handle
disequalities between terms such as $t_1 \neq t_2$.  The typical
Prolog resources for handling these disequalities are limited to the
built-in predicate {\tt /== /2}, which needs both terms to be ground
because it always succeeds in the presence of free variables.  It is
clear that a variable needs to be bound with a disequality to achieve
a ``constructive'' behaviour.  Moreover, when an equation $X =
t(\overline{Y})$ is negated, the free variables in the equation must
be universaly quantified, unless affected by a more external
quantification, i.e. $\forall~ \overline{Y}~X \neq t(\overline{Y})$ is
the correct negation.  As we explained in \cite{SusanaPADL2000}, the
inclusion of disequalities and constrained answers has a very low
cost. It incorporates negative normal form constraints instead of
bindings and the decomposition step can produce disjunctions. Our
proposal for normal form constraints is:

%\vspace{-20pt}
\[ \underbrace{\bigwedge_i (X_i = t_i)}_{\mbox{positive information}} \wedge~~~~ ( \underbrace{\bigwedge_j \forall~ \overline{Z}_j^1~(Y_j^1 \neq s_j^1) \vee \ldots \vee \bigwedge_l \forall~ \overline{Z_l}^n~(Y_l^n \neq s_l^n) ) }_{\mbox{negative information}} \]
%\vspace{-20pt}

\noindent
where each $X_i$ appears only in $X_i = t_i$, no $s_k^r$ is $Y_k^r$
and the universal quantification could be empty (leaving a simple
disequality).

It is easy to see that some normalization rules can be defined for a
normal form formula from any initial formula. The redefinition of the
unification algorithm to manage constrained variables is also a simple
exercise.

\cite{Moreno1} introduces this very compact way to represent a normal
form constraint.  Chan's representation uses only disjunctions and
they are dealt with by means of backtracking. The main advantage of our
normal form is that the search space is drastically reduced.

To include disequalities into a Prolog compiler, we need to just
reprogram unification. This can be done using attributed variables
\cite{Carlsson} (available in several Prolog versions, e.g. in Sicstus
Prolog, or in Eclipse, where they are called meta-structures). These
variables allow us to keep information associated with each variable
(in an attibute that is a term) during the unification, which can be
used to dynamically control the constraints.

%% Attributed variables are variables with an associated attribute.  which
%% is a term. Each variable has an associated data structure, containing a
%% normal form constraint: a list of lists of pairs (variable, term). They
%% behave like ordinary variables, except that the programmer can supply
%% code for unification, printing facilities and memory management. In
%% our case, the printing facility is used to show constrained
%% answers. The main task is to provide a new unification code.

For the unification of a variable $X$ with a term $t$, there are three
possible cases (up to commutativity):

%\vspace{-5pt}
\begin{enumerate}
%\addtolength{\itemsep}{-8pt}

   \item $X$ is a free variable and $t$ is not a variable with a
   negative constraint: just bind $X$ to $t$,

   \item $X$ is a free variable or bound to a term $t'$ and $t$ is a
   variable $Y$ with a negative constraint: check whether $X$ (or,
   equivalently, $t'$) satisfies the constraint associated with $Y$.
   A conveniently defined predicate {\tt satisfy} is used for this
   purpose,

   \item $X$ is bound to a term $t'$ and $t$ is a term (or a variable
   bound to a term): use the classical unification algorithm.

\end{enumerate}
%\vspace{-5pt}

A Prolog predicate {\tt =/= /2} \cite{SusanaPADL2000} has been
defined, used to check disequalities, similarly to explicit
unification ({\tt =}). Each constraint is a disjunction of
conjunctions of disequalities that are implemented as a list of lists
of terms like $T_1/T_2$ (which represents the disequality $T_1 \neq
T_2$). When a universal quantification is used in a disequality (e.g.,
$\forall Y~ X \neq c(Y)$), the new constructor {\tt fA}$/1$ is used
(e.g., {\tt X / c(fA(Y)))}.  The first list is used to represent
disjunctions while the internal list represents the conjunction of
disequalities.

Let us show some examples involving variable $X$ where we show the
corresponding attribute that represents the constraint of each
subgoal:

%\hspace{-0.5cm}
\begin{center}
\begin{small}
\begin{tabular}{lll}
SUBGOAL & ATTRIBUTE & CONSTRAINT \\
\hline\hline
\ \\
{\tt not\_member(X,[1,2,3])}   &  $X=/=1,X=/=2,X=/=3$  & $X \neq 1 \wedge X \neq 2 \wedge X \neq 3$\\
{\tt member(X,[1,2,3]),X=/=2} &  $X=/=1,X=/=3$       & $X \neq 1 \wedge X \neq 3$\\
{\tt member(X,[1]), X=/=1}     &  {\tt fail}          & $false$ \\
{\tt X =/= 4}                   & $X=/=4$            & $X \neq 4$ \\
{\tt X =/= 4; X=/=5}            & $X=/=4~ ;~ X/5$     & $X \neq 4 \vee X \neq 5$ \\
{\tt X =/= 5; (X=/=6, X=/=Y)}   & $X=/=5 ~; ~ (X=/=6, X=/=Y)$ & $X \neq 5 \vee (X \neq 6 \wedge X \neq Y)$\\
{\tt forall([Y], X =/= s(Y))}     & $X=/=s(fA(Y)$  & $\forall Y. X \neq Y$ \\
%{\tt (member (X,[0,s(0),s(s(0))]),} &                  & \\
%{\tt forall (Y, X =/= s (Y)) )}     & $0$              & $X = 0$
\end{tabular}
\end{small}
\end{center}



%%%%%%%% OPTIMIZATION  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Optimizing the algorithm and the implementation}
\label{optimization}

Our constructive negation algorithm and the implementation techniques
admit some additional optimizations that can improve the runtime
behaviour of the system. Basically, the optimizations rely on the
compact representation of information, as well as the early detection
of successful or failing branches.

\noindent
{\bf Compact information}. In our system, negative information is
represented quite compactly, providing fewer solutions from the
negation of $\overline{I}$. The advantage is twofold. On the one hand
constraints contain more information and failing branches can be
detected earlier (i.e. the search space could be smaller). On the
other hand, if we ask for all solutions using backtracking, we are
cutting the search tree by offering all the solutions together in a
single answer. For example, we can offer a simple answer for the
negation of a predicate $p$ (the code for $p$ is skipped):

\begin{verbatim}
?- cneg(p(X,Y,Z,W)).

(X=/=0, Y=/=s(Z)) ; (X=/=Y) ; (X=/=Z) ; 
(X=/=W) ; (X=/=s(0), Z=/=0) ? ;
no
\end{verbatim}

\noindent
(which is equivalent to $ (X \neq 0 \wedge Y\neq s(Z)) \vee X \neq Y
\vee X \neq Z \vee X \neq W \vee X \neq s(0) \vee Z \neq 0$),
instead of returning six answers upon backtracking:
\begin{verbatim}
?- cneg(p(X,Y,Z,W)).

X=/=0, Y=/=s(Z) ? ;
X=/=Y ? ;
X=/=Z ? ;
X=/=W ? ;
X=/=s(0) ? ;
Z=/=0 ? ;
no
\end{verbatim}


\noindent
{\bf Pruning subgoals}. The frontiers generation search tree can be
cut with a double action over the ground subgoals: removing the
subgoals whose failure we are able to detect early on, and simplifying the
subgoals that can be reduced to true. Suppose  we have a predicate $p/2$
defined as
\begin{verbatim}
p(X,Y):- greater(X,Y),
         q(X,Y,Z),
         r(Z).
\end{verbatim}
\noindent
where $q/3$ and $r/1$ are predicates defined by several
clauses with a complex computation. To negate
the goal $p(s(0),s(s(0)))$, its frontier is computed:

$$Frontier(p(s(0),s(s(0)))) \equiv $$
$${ X=s(0) \wedge Y=s(s(0)) \wedge
  greater(X,Y) \wedge q(X,Y,Z) \wedge r(Z) } \equiv $$
$${ greater(s(0),s(s(0))) \wedge q(s(0),s(s(0)),Z) \wedge r(Z) } \equiv $$
$${ fail  \wedge q(s(0),s(s(0)),Z) \wedge r(Z) } \equiv $$
$$fail $$

The next step is to expand the code of the subgoals of the frontier to
the combination (disjunction) of the code of all their clauses, and the
result will be a very complicated and hard to check frontier.
However, the process is optimized by evaluating ground terms. In this
case, $greater(s(0),s(s(0))$ fails and, therefore, it is not necessary to
continue with the generation of the frontier, because the result is
reduced to fail (i.e. the negation of $p (s(0), s(s(0)))$ will be
trivially true). The opposite example is a simplification:

$$Frontier(p(s(s(0)),s(0))) \equiv $$
$${ X=s(s(0)) \wedge Y=s(0) \wedge greater(X,Y) \wedge q(X,Y,Z) \wedge
  r(Z) } \equiv $$
$${ greater(s(s(0)),s(0)) \wedge q(s(s(0)),s(0),Z) \wedge r(Z) } \equiv
$$
$${ true \wedge q(s(s(0)),s(0),Z) \wedge r(Z) } \equiv $$
$${ q(s(s(0)),s(0),Z) \wedge r(Z) } $$

\noindent
{\bf Constraint simplification}. During the whole process for negating
a goal,the frontier variables are constrained. In cases where the
constraints are satisfiable, they can be eliminated and where the
constraints can be reduced to fail, the evaluation can be stopped with
result \emph{true}.
 
We focus on the negative information of a normal form constraint $F$:
\[ F \equiv  \bigvee_i\bigwedge_j \forall~ \overline{Z}_j^i~(Y_j^i \neq s_j^i) \]
Firstly, the Prenex form \cite{Shoenfield} can be obtained by
extracting the universal variables with different names to the head of
the formula, applying logic rules:
\[ F \equiv \forall \overline{x} \bigvee_i\bigwedge_j (Y_j^i \neq s_j^i) \]
\noindent
and using the distributive property:
\[ F \equiv \forall \overline{x} \bigwedge_k\bigvee_l (Y_l^k \neq s_l^k) \]
The formula can be separated into subformulas that are simple
disjunctions of disequalities :
\[ F \equiv \bigwedge_k \forall \overline{x} \bigvee_l (Y_l^k \neq s_l^k) \equiv F_1 \wedge ... \wedge F_n\]
Each single formula $F_k$ can be evaluated. The first step will be to
substitute the existentially quantified variables (variables that do not
belong to $\overline{x}$) by Skolem constants $s^i_j$ that will keep
the equivalence without losing generality:
\[ F_k \equiv \forall \overline{x} \bigvee_l ( Y_l^k \neq s_l^k ) \equiv \forall \overline{x} \bigvee_l ( Y_{Sk l}^k \neq s_{Sk l}^k )  \]
Then it can be transformed into:
\[ F_k \equiv  \neg \exists ~ \overline{x} \neg ( \bigvee_l (Y_{Sk l}^k \neq s_{Sk l}^k) ) \equiv \neg Fe_K \]
The meaning of $F_k$ is the negation of the meaning of $Fe_k$;
\[ Fe_k \equiv \exists ~ \overline{x} \neg ( \bigvee_l (Y_{Sk l}^k \neq s_{Sk l}^k)) \] 
Solving the negations, the result is obtained through simple unifications of the variables of $\overline{x}$:

\[ Fe_k  \equiv \exists ~ \overline{x} \bigwedge \neg (Y_{Sk l}^k \neq s_{Sk l}^k)  \equiv \exists ~ \overline{x} \bigwedge (Y_{Sk l}^k = s_{Sk l}^k)  \]

        Therefore, we get the truth value of $F_k$ from the
        negation of the value of $Fe_k$ and, finally, the value of $F$ is
        the conjunction of the values of all $F_k$. If $F$
        succeeds, then the constraint is removed because it is redundant
        and we continue with the negation process. If it fails, then
        the negation directly succeeds.

%%%%%%%%%%%%%%%%%%%%%%%% RESULTS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Experimental results}
\label{results}
This section reports some experimental results from our prototype
implementation.  First of all, we show the behaviour of the
implementation in some simple examples.

%%%%%%%% EXAMPLES  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Examples}
\label{examples}

The interesting side of this implementation is that it returns
constructive results from a negative question. Let us start with a
simple example involving predicate $boole/1$.

\begin{minipage}{2in}
\begin{verbatim}
boole(0).
boole(1).
\end{verbatim}
\end{minipage}
\begin{minipage}{2in}
%\rnode{A}{}
\begin{verbatim} 

    ?- cneg(boole(X)).
    X=/=1, X=/=0 ? ;
    no
\end{verbatim} 
%\rnode{B}{}
%\ncline{A}{B}
\end{minipage}\\

Another simple example obtained from \cite{Stuckey95} gives us the
following answers:

\begin{minipage}{2in}
\begin{verbatim}
p(a,b,c).
p(b,a,c).
p(c,a,b).

proof1(X,Y,Z):-
    X =/= a,
    Z = c,
    cneg(p(X,Y,Z)).
\end{verbatim}
\end{minipage}
\begin{minipage}{2in}
\begin{verbatim} 

   ?- proof1(X,Y,Z).

   Z = c,
   X=/=b, X=/=a ? ;

   Z = c,
   Y=/=a, X=/=a ? ;

   no
\end{verbatim} 
\end{minipage}\\

\cite{Stuckey95} contains another example showing how a constructive
answer ($\forall T ~ X \neq s(T)$) is provided for the negation of an
undefined goal in Prolog:

\begin{minipage}{2in}
\begin{verbatim}

p(X):- X = s(T), q(T).

q(T):- q(T).

r(X):- cneg(p(X)).
\end{verbatim}
\end{minipage}
\begin{minipage}{2in}
\begin{verbatim} 
   ?- r(X).

   X=/=s(fA(_A))

\end{verbatim} 
\end{minipage}\\



Examples that have an infinite number of solutions are more
interesting.

\begin{minipage}{1.5in}
\begin{verbatim}
positive(0). 
positive(s(X)):-
        positive(X).  
\end{verbatim}
\end{minipage} 
\begin{minipage}{2.5in}
%\rnode{A}{}
\begin{verbatim} 

    ?- cneg(positive(X)).

    X=/=s(fA(_A)), X=/=0 ? ;
    X = s(_A), 
    (_A=/=s(fA(_B)), _A=/=0) ? ;
    X = s(s(_A)), 
    (_A=/=s(fA(_B)), _A=/=0) ? ;
    X = s(s(s(_A))),
    (_A=/=s(fA(_B)), _A=/=0) ? 
    yes
\end{verbatim} 
%\rnode{B}{}
%\ncline{A}{B}
\end{minipage}

\begin{minipage}{1.5in}
\begin{verbatim}
number(0).
number(s(X)):-
        number(X).

greater(s(X),0):-
        number(X).
greater(s(X),s(Y)):-
        greater(X,Y).
\end{verbatim}
\end{minipage}
\begin{minipage}{2.5in}
%\rnode{A}{}
\begin{verbatim} 
    ?- cneg(greater(X,Y)).

    Y=/=0, Y=/=s(fA(_A)) ? ;

    (Y=/=s(fA(_A))), 
    (X=/=s(fA(_B))) ? ;

    X = s(_A),Y = 0,
    (_A=/=s(fA(_B)),_A=/=0) ? ;

    X = s(s(_A)),Y = 0,
    (_A=/=s(fA(_B)),_A=/=0) ? ;

    X = s(s(s(_A))),Y = 0,
    (_A=/=s(fA(_B)),_A=/=0) ? ;

    X = s(s(s(s(_A)))),Y = 0,
    (_A=/=s(fA(_B)),_A=/=0) ? 

    yes
\end{verbatim} 
%\rnode{B}{}
%\ncline{A}{B}
\end{minipage}

\subsection{Implementation measures}

We have firstly measured the execution times in milliseconds for the
above examples when using negation as failure ($naf/1$) and
constructive negation ($cneg/1$). A `-' in a cell means that negation
as failure is not applicable. All measurements were made using \ciao\
Prolog\footnote{The negation system is coded as a library module
(``package'' \cite{ciao-modules-cl2000}), which includes the
respective syntactic and semantic extensions (i.e. Ciao's
attributed variables). Such extensions apply locally within each
module which uses this negation library.} 1.5 on a Pentium II at 350
Mhz. The results are shown in Table~\ref{table}. We have added a first
column with the runtime of the evaluation of the positive goal that is
negated in the other columns and a last column with the ratio that
measures the speedup of the \naf\ technique w.r.t. constructive
negation.

Using {\bf naf} instead of {\bf cneg} results in small ratios around
1.06 on average for ground calls with few recursive calls. So, the
possible slow-down for constructive negation is not so high as we
might expect for these examples. Furthermore, the results are rather
similar. But the same goals with data that involve many recursive
calls yield ratios near 14.69 on average w.r.t {\bf naf},
increasing exponentially with the number of recursive calls. There
are, of course, many goals that cannot be negated using the \naf\
technique and that are solved using constructive negation.

\input{table} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%% CONCLUSIONS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{-1em}
\section{Conclusion and Future Work}
\label{conclusion}
\vspace{-1em}
After running some preliminary experiments with the constructive 
negation technique  following Chan's description, we realized that the
algorithm needed some additional explanations and modifications.

Having given a detailed specification of algorithm in a detailed way
we proceed to provide a real, complete and consistent
implementation. The result, we have reported are very encouraging,
because we have proved that it is possible to extend Prolog with a
constructive negation module relatively inexpensively. Nevertheless,
it is quite important to address possible optimizations, and we are
working to improve the efficiency of the implementation. These include
a more accurate selection of the frontier based on the demanded form
of argument in the vein of \cite{Moreno2}). Other future work is to
incorporate our algorithm at the WAM machine level.

In any case, we will probably not be able to provide an efficient enough
implementation of constructive negation, because the algorithm is
inherently inefficient.  This is why we do not intend to
use it either for all cases of negation or for negating goals
directly.

Our goal is to design and implement a practical negation operator and
incorporate it into a Prolog compiler.
In~\cite{SusanaPADL2000,SusanaLPAR01} we systematically studied what
we understood to be the most interesting existing proposals: negation
as failure (\naf) \cite{Clark}, use of delays to apply \naf\
securely~\cite{naish:lncs}, intensional
negation~\cite{Barbuti1,Barbuti2}, and constructive negation
\cite{Chan1,Chan2,Drabent,Stuckey,Stuckey95}. As none of them can
satisfy our requirements of completeness and efficiency, we propose to
use a combination of these techniques, where the information from
static program analyzers could be used to reduce the cost of selecting
techniques \cite{SusanaLPAR01}. So, in many cases, we avoid the
inefficiency of constructive negation. However, we still need it
because it is the only method that is sound and complete for all kinds
of goal. For example, looking at the goals in Table~\ref{table}, the
strategy will obtain all ground negation using the \naf\ technique and
would only use constructive negation for the goals with variables
where it is impossible to use \naf\ .

We are testing the implementation and trying to improve the code, and
our intention is to include it in the next version of Ciao Prolog
\footnote{http://www.clip.dia.fi.upm.es/Software}.
  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% BIBLIOGRAPHY %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

 \begin{small}

% \linespread{0.80}
    \bibliographystyle{plain} 
    \bibliography{bibliography}

 \end{small}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%  THE END  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

