%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Implementation of Constructive Negation for Prolog 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{llncs}

%% \newenvironment{mytabbing}
%%    {\vspace{0.3em}\begin{small}\begin{tabbing}}
%%    {\end{tabbing}\end{small}\vspace{0.3em}}

%%\newenvironment{mytabbing}
%%   {\begin{tabbing}}
%%   {\end{tabbing}}

\usepackage{pst-node}

\newcommand{\naf}{{\em naf}}\newcommand{\viejo}[1]{}
\newcommand{\ciao}{Ciao}


\newcommand{\tab}{\hspace{2em}}
\newcommand{\ra}{$\rightarrow~$}
\newcommand{\Ra}{\Rightarrow~}
\newcommand{\HINT}{{\cal H\!-\!INT}}
%\newcommand{\cts}{\mid}
\newcommand{\cts}{~[\!]~}
\newcommand{\N}{I\!\!N}

\newcommand{\ToDo}[1]{
  \begin{center}
      \begin{minipage}{0.75\textwidth}
        \hrule
        \textbf{To do:}\\
        {\em #1}
        \hrule
      \end{minipage}\\
  \end{center}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Constructive Negation for Prolog:}
\subtitle{A Real Implementation}

\author{~~Susana Mu\~{n}oz~~ \and ~~ Juan Jos\'{e} Moreno-Navarro \\
         \email{susana@fi.upm.es}~~~~~~~~~~ \email{jjmoreno@fi.upm.es}}

\institute{ 
LSIIS, Facultad de Inform\'{a}tica \\
Universidad Polit\'{e}cnica de  Madrid \\ 
Campus de Montegancedo s/n Boadilla del Monte\\
28660 Madrid, Spain \footnote{This work was partly supported by the Spanish MCYT project TIC2000-1632.} \\
 }

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-12pt}

%



\begin{abstract}
  Logic Programming has been advocated as a language for system
  specification, specially those involving logical behaviors, rules
  and knowledge. However, modeling problems involving negation, quite
  natural in many cases, has some limitations if Prolog is used as the 
specification/implementation language. The restrictions do not
  come from the theoretical viewpoint, where the user can find many
  different models with the corresponding semantics, but from
  practical implementation issues.  The negation capabilities supported by
  current Prolog systems are rather limited from the constructive
  point of view.  In this paper, we refine and propose some extensions
  to the method of constructive negation, providing the complete
  theoretical algorithm, and we also discuss about implementation
  issues providing a preliminary implementation.
\end{abstract}

\paragraph{\bf Keywords}
Constructive Negation, Negation in Logic Programming, Constraint Logic
Programming, Implementations of Logic Programming.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%% INTRODUCTION %%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{introduction}
From its very beginning Logic Programming has been advocated to be
either a programming language and a specification language.  It seems
to be natural to use Logic Programming for specifying/programming
systems involving logical behaviors, rules and knowledge. However,
this idea has a strong limitation: the use of negation.  Probably,
negation is the most significant aspect of logic that was not included
from the outset. This is due to the fact that dealing with negation
involves significant additional complexity.  Nevertheless the use of
negation is very natural and plays an important role in many cases,
for instance management of constraints in databases, program
composition, manipulation and transformation, default reasoning, etc.

% Work done in negation
This restriction cannot be perceived from the theoretical point of
view because there are many alternative ways to understand and
incorporate negation into Logic Programming. The related problems
start already at the semantic level and the different proposals
(negation as failure (\naf), stable models, well founded semantics,
explicit negation, etc.)  differ not only in expressiveness but also
in semantics.  However, the negation techniques supported by current
Prolog compilers are rather limited, restricted to Negation as failure
under the Fitting/Kunen semantics \cite{Kunen} (sound only under some
circumstances) that is a built-in or library in most Prolog compilers
(Quintus, SICStus, Ciao, BinProlog, etc.), and the ``delay technique''
(applying negation as failure only \emph{when} the variables of the
negated goal become ground, which is sound but incomplete due to the
possibility of floundering) that is present in Nu-Prolog, G\"odel, and
Prolog systems which implement delays (most of those above).

Among all the mentioned proposals, constructive negation is probably the most 
promising because it is proved to be sound and complete and
its semantics is fully compatible with the Prolog one. In fact, 
constructive negation was announced in early versions of the 
Eclipse Prolog compiler, but was removed from the last releases.
The reasons seem to be related with some technical problems with the use
of coroutining (risk of floundering) and the management of constrained answers.


The goal of this paper is to describe a description of constructive negation
in an algorithmic way, i.e. making explicit the details needed for an 
implementation. We want also to discuss the pragmatic ideas needed to
provide a concrete and real implementation. Early results for a concrete 
implementation extending the \ciao\ Prolog compiler are presented.
% Quizas dar alguna idea adicional de la estrategia

% Organization   !!!!!!!!!!!!!!!!!! Rehacer esto de las secciones

The rest of the paper is organized as follows. Section
\ref{constructive} describe in detail our constructive negation
algorithm. It tells how to obtain the $frontier$ of a goal (Section
\ref{frontier}), how to prepare it to be negated (Section
\ref{preparation}) and finally how to negate it (Section
\ref{negation}). Section \ref{implementation} talks about
implementation issues: the code expansion (Section \ref{expansion}),
the disequality constraints (Section \ref{disequality}) that are
needed, optimizations (Section \ref{optimization}), examples (Section
\ref{examples}) and some experimental results (Section \ref{results}).
Finally we conclude and sketch some future work.
 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%   CONSTRUCTIVE NEGATION   %%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Constructive Negation}
\label{constructive}

Most of the papers devoted to constructive negation deal 
with semantical aspects. In fact, only the original papers by Chan gave some hints
about a possible implementation based on coroutining, but the
technique was just sketched. When we have tried to reconstruct it we
have found several problems including floundering (in fact it seems to
be the reason why constructive negation was removed from recent
Eclipse versions) and the management of constrained answers. 
Our claim is that it is not possible to overcome this problems in an easy
and efficient way.
Thus, we decided to design an implementation from
scratch.  One of our additional requirements is 
that we want to use a standard Prolog implementation, so we
will avoid implementation-level manipulations.

We first start with the definition of a frontier and how to manage it for
negating the corresponding formula.

%%%%%%%%% FRONTIER  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Frontier}
\label{frontier}

We first start with Chan's definition of frontier (in fact, 
the formal definition is due to Stuckey \cite{Stuckey95}). 

\begin{definition}{\em Frontier}

A frontier of a goal $G$ is a finite set of nodes in the derivation tree
such that every derivation of $G$ is either finitely failed or passes
through exactly one {\em frontier node}.
\end{definition}

What is missing is a method to generate the frontier.  Up to now we
are using the simplest possible frontier: the frontier of depth 1
obtained by doing all possible single steps of SLD resolution. Simple
inspection of the applicable clauses can do this\footnote{Nevertheless, we
plan to improve it by using abstract interpretation and
detecting the degree of evaluation of a term that the execution will
generate.}.
Additionally, built-in based goals have a special
treatment (moving conjunctions into disjunctions, disjunctions into
conjunction, eliminating double negations, etc.)

\begin{definition}{\em Depth-one frontier}

    \begin{itemize} 

\item If $G \equiv (G_1;G_2) $ then $Frontier(G) \equiv$
$Frontier(G_1) \vee Frontier(G_2)$.

\item If $G \equiv (G_1,G_2) $ then $Frontier(G) \equiv$
  $Frontier(G_1) \wedge Frontier(G_2)$ and then we have to apply the
  distributive property of DeMorgan to keep the disjunction of
  conjunctions format.
  
\item If $G \equiv p( \overline{X}) $ and 
  predicate $p/n$ is defined by N clauses:

$
~~~~~~~~~~p( \overline{X}^1):- C_1'. \\
~~~~~~~~~~p( \overline{X}^2):- C_2'. \\
~~~~~~~~~~\ldots \\
~~~~~~~~~~p( \overline{X}^3):- C_N'. \\
$

The frontier of the goal has the format:
$Frontier(G) \equiv \{C_1 \vee C_2 \vee \ldots \vee C_N\}$, 
where each $C_i$ is the join
of the conjunction of subgoals $C_i'$ plus the equalities that are
needed to get the unification between the variables of $\overline{X}$
and the corresponding terms of $\overline{X}^i$.

    \end{itemize}

\end{definition}

Consider, for instance, the following code:

\begin{verbatim}
odd(s(0)).
odd(s(s(X))) :- odd(X).
\end{verbatim}

The frontier for the goal $odd (Y)$ is the following:

\[Frontier(odd(Y)) = \{ ( Y=s(0) ) \vee ( Y=s(s(X)) \wedge odd(X) ) \} \] 

To obtain the negation of $G$ is enough to negate the frontier
formula. This is done by negating each component of the disjunction of
all implied clauses (that form the frontier) and combining the
results.


The solutions of $cneg(G)$ are the solutions of the combination
(conjunction) of one solution of each of the N conjunctions
$C_i$. From now we are going to explain how to negate a single
conjunction $C_i$.



%%%%%%%% PREPARATION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Preparation}
\label{preparation}

% Comparar con Chan

Before negating a conjunction obtained from the frontier we have to
simplify, organize, and normalize it:

\begin{itemize}

\item {\bf Simplification of the conjunction}. If one of the terms of
$C_i$ is trivially equivalent to 
$true$ (e.g. $X=X$) we can eliminate it from $C_i$, and if
one of the terms is trivially $fail$ing (e.g. $X \neq X$) we can simplify $C_i
\equiv fail$. This simplification is carried during the process
of generation of terms of the frontier.

\item {\bf Organization of the conjunction}. We make three groups with
the components of $C_i$ to divide them in equalities, disequalities
and the rest of subgoals. Then we obtain $C_i \equiv \overline{I}
\wedge \overline{D} \wedge \overline{R}$ where $\overline{I}$ is the
set of equalities, $\overline{D}$ is the set of disequalities (that
appear explicitly in $C_i'$) and $\overline{R}$ is the rest of subgoals.
  
\item {\bf Normalization of the conjunction}. The set of variables of the
goal is called $GoalVars$. The set of free variables of $\overline{R}$
is called $RelVars$.

    \begin{itemize}


       \item {\bf Elimination of redundant variables and
       equalities}. If $I_i \equiv X = Y$ where $Y \not\in GoalVars$
       then we have now the formula $ ( I_1 \wedge \ldots \wedge
       I_{i-1} \wedge I_{i+1} \wedge \ldots \wedge I_{NI} \wedge
       \overline{D} \wedge \overline{R}~) \sigma $ where $ \sigma = \{
       Y / X \}$, i.e. the variable $Y$ is substituted by $X$ in the
       entire formula. 
       \item {\bf Elimination of irrelevant disequalities}. The set of
       variables of $GoalVars$ and the variables that appear in
       $\overline{I}$ are called jointly $ImpVars$. The disequalities
       $D_i$ which contain any variable that wasn't in $ImpVars$
       neither $RelVars$ are irrelevant and must be eliminated.

    \end{itemize}

 \end{itemize}

 

%%%%%%%% NEGATION OF THE FORMULA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Negation of the formula}
\label{negation}

To obtain all solutions of $C_i$ and to negate them is not possible
because $C_i$ can have an infinite number of solutions. So we have to
use the general constructive negation algorithm.  

We consider that $ExpVars$ is the set of variables of $\overline{R}$
that aren't in $ImpVars$, i.e. $RelVars$ except the variables of
$\overline{I}$ of the normalized formula.
\medskip

\noindent
{\em First step: {\bf Division of the formula}}

\noindent
We have to divide $C_i$ in its sub-parts:

\[C_i \equiv \overline{I} \wedge
        \overline{D}_{imp} \wedge \overline{R}_{imp} \wedge
        \overline{D}_{exp} \wedge \overline{R}_{exp} \]

\noindent
where $\overline{D}_{exp}$ are the disequalities in $\overline{D}$
with variables in $ExpVars$ and $\overline{D}_{imp}$ are the rest of
disequalities, $\overline{R}_{exp}$ are the goals of $\overline{R}$
with variables in $ExpVars$ and $\overline{R}_{imp}$ are the rest of
goals, and $\overline{I}$ are the equalities.

Therefore the constructive negation of the divided formula will be: \\

$~~~~~~~~~~~~~~~~~~~~\neg~C_i \equiv \neg~\overline{I} \vee $ \\
$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(\overline{I} \wedge \neg~\overline{D}_{imp}) \vee  $ \\
$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(\overline{I} \wedge \overline{D}_{imp} \neg~\overline{R}_{imp}) \vee $ \\
$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~( \overline{I} \wedge \overline{D}_{imp} \wedge \overline{R}_{imp} \wedge \neg~(\overline{D}_{exp} \wedge \overline{R}_{exp})) $ \\

It is not possible to separate $\overline{D}_{exp}$ and
$\overline{R}_{exp}$ because they contain free variables and
their negation cannot be done separately. The answers of the negations
will be the answers of the negation of the equalities, the answers of
the negation of the disequalities without free variables, the answers
of the negation of the subgoals without free variables and the answers
of the negation of the rest of subgoals of the conjunctions (the ones
with free variables). Each of them will be obtained as follow:
\medskip

\noindent
{\em Step2: {\bf Negation of subformulas}}

        \begin{itemize}

           \item {\bf Negation of $\overline{I}$}. We have $\overline{I}
           \equiv I_1 \wedge \ldots \wedge I_{NI} \equiv$ \[ \exists~
           \overline{Z}_1~ X_1 = t_1 \wedge \ldots \wedge \exists~
           \overline{Z}_{NI}~ X_{NI} = t_{NI} \] where
           $\overline{Z}_i$ are the variables of the equality $I_i$ that
           aren't included in $GoalVars$ (i.e. that aren't quantified
           and therefore are free variables). When we negate this
           conjunction of equalities we obtain the constraint 
                \[
           \underbrace{\forall~ \overline{Z}_1~ X_1 \neq t_1} _{\neg~
           I_1} \vee \ldots \vee \underbrace{\forall~
           \overline{Z}_{NI}~ X_{NI} \neq t_{NI} } _{\neg~ I_{NI}}
           \equiv %\] 
%                \[ 
           \bigvee_{i=1}^{NI} \forall~ \overline{Z}_i X_i
           \neq t_i \] 
           This constraint is the first answer of the
           negation of $C_i$ that contains $NI$ solutions.

           \item {\bf Negation of $\overline{D}_{imp}$}. If we have
           $N_{D_{imp}}$ disequalities $\overline{D}_{imp} \equiv D_1
           \wedge \ldots \wedge D_{N_{D_{imp}}}$ where $ D_i \equiv
           \forall~ \overline{W}_i ~ \exists~ \overline{Z}_i ~ Y_i
           \neq s_i$ where $Y_i$ is a variable of $ImpVars$, $s_i$ is
           a term without variables in $ExpVars$, $\overline{W}_i$ are
           universally quantified variables that are neither in the
           equalities \footnote{of course, there are no universally
           quantified variables into an equality}, nor in the rest of
           the goals of $\overline{R}$ because then it will be a
           disequality of $\overline{D}_{exp}$. Then we will get
           $N_{D_{imp}}$ new solutions with the format: \\

           $\overline{I} \wedge \neg~ D_1 $ \\ 
           $\overline{I} \wedge
           D_1 \wedge \neg~ D_2 $ \\ 
           $\ldots $ \\ 
           $\overline{I} \wedge
           D_1 \wedge \ldots \wedge D_{N_{D_{imp}}-1} \wedge \neg~
           D_{N_{D_{imp}}}$ \\ 

           where $ \neg~ D_i \equiv \exists~
           \overline{W}_i~ Y_i = s_i$. The negation of an universally
           quantification turns on existentially quantification and
           the quantification of free variables of $\overline{Z}_i$
           get lost because they are unified with the evaluation of
           the equalities of $\overline{I}$. Then we will get
           $N_{D_{imp}}$ new answers.


           \item {\bf Negation of $\overline{R}_{imp}$}. If we have
           $N_{R_{imp}}$ subgoals $\overline{R}_{imp} \equiv R_1
           \wedge \ldots \wedge R_{N_{R_{imp}}}$. Then we will get
           new answers from each of the conjunctions: \\

           $\overline{I} \wedge \overline{D}_{imp} \wedge \neg~ R_1 $ \\ 
           $\overline{I} \wedge \overline{D}_{imp} \wedge
           R_1 \wedge \neg~ R_2 $ \\ 
           $\ldots $ \\ 
           $\overline{I} \wedge \overline{D}_{imp} \wedge
           R_1 \wedge \ldots \wedge R_{N_{R_{imp}}-1} \wedge \neg~
           R_{N_{R_{imp}}}$ \\ 

           where $ \neg~ R_i \equiv cneg(R_i)$. It is again the
           constructive negation that is applied over $R_i$
           recursively.


           \item {\bf Negation of $\overline{D}_{exp} \wedge
           \overline{R}_{exp}$}. This conjunction can't be disclosed
           because the negation of $ \exists~ \overline{V}_{exp}~
           \overline{D}_{exp} \wedge \overline{R}_{exp}$, where
           $\overline{V}_{exp}$, gives universal quantifications:
           $\forall~ \overline{V}_{exp}~ cneg(\overline{D}_{exp}
           \wedge \overline{R}_{exp})$. Now the complete algorithm of
           constructive negation must be applied again. The set
           $GoalVars$ that we are going to consider therefore is the
           former set $ImpVars$. Variables of $\overline{V}_{exp}$ are
           considered as free variables. When solutions of
           $cneg(\overline{D}_{exp} \wedge \overline{R}_{exp})$ will
           be obtained, then we will reject solutions with equalities
           with variables of $\overline{V}_{exp}$. When there will be
           a disequality with any of these variables, e.g. $V$, the
           variable will be universally quantified in the disequality.
           This is the treatment to negate the negation of a goal but
           there is a detail that wasn't consider in former approaches
           and that is necessary to obtain a sound implementation: the
           existence of universally quantified variables in
           $\overline{D}_{exp} \wedge \overline{R}_{exp}$ by the
           iterative application of the method.  So, what we are
           really negating is a subgoal of the form: $ \exists~
           \overline{V}_{exp}~ \overline{D}_{exp} \wedge
           \overline{R}_{exp}$.  Here we will provide the last group
           of answers that come from:

           \[\overline{I} \wedge \overline{D}_{imp}
           \wedge \overline{R}_{imp} \wedge \forall~
           \overline{V}_{exp}~ \neg~(\overline{D}_{exp} \wedge
           \overline{R}_{exp})\]

         \end{itemize}


    

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%  IMPLEMENTATION ISSUES  %%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Implementation Issues}
\label{implementation}

Once we have described the theoretical algorithm, including relevant
details, we supply important aspects for a practical implementation,
including how to compute the frontier and the management of answer
constraints.

%%%%%%%% CODE EXPANSION  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Code Expansion}
\label{expansion}

The first thing we have to do to implement this technique is obtaining
the frontier of a goal. For this purpose is necessary that the code of
the implied predicates is available during execution to construct the
frontier. It is possible to handle the code of clauses during the
execution thanks to the package system of Ciao
\cite{ciao-modules-cl2000} that let us to expand the code at run time.
Therefore we have been able to evaluate and execute predicates and
provide their code at the same time to calculate their $Frontiers$ at
any step of the algorithm. The expansion is implemented in the package
$cneg.pl$ that is incorporated in the declaration of the module that
is going to be expanded (i.e. where there are goals that are
negations).

A simple example would be the module $mod1.pl$ that export the
predicate $odd/1$ and the predicate $not_odd/1$ that is semantically
the negation of $odd/1$:
\begin{verbatim}
:- module(mod1,[odd/1,not_odd/1],[cneg]).

odd(s(0)).
odd(s(s(X))) :- odd(X).

not_odd(X) :- cneg(odd(X)).
\end{verbatim}
The loading of the package $cneg.pl$ means 
that the compiler works with a expanded code added to the previous one:
\begin{verbatim}
stored_clause(odd(s(0)),[]).
stored_clause(odd(s(s(X))),[odd(X)]).
\end{verbatim}
where information about structure of code is stored to be used by the
negation algorithm. Now the execution is able to compute the frontier
we describe above $\{ ( Y=s(0) ) \vee ( Y=s(s(X)) \wedge odd(X) ) \}$

% The cuestion is how to expand this to the code imported from diferent 
% modules.This is an extension: ``Modular Constructive Negation'' 

%%%%%%%% DISEQUALITY CONSTRAINTS  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Disequality constraints}
\label{disequality}

An instrumental step in order to manage negation 
is to be able to handle disequalities between terms such as $t_1
\neq t_2$.  Prolog implementations typically include only the built-in
predicate {\tt /== /2} % es \ pero no me funciona
 which can only work with disequalities if both
terms are ground and simply succeeds in the presence of free variables.
A ``constructive'' behavior must allow the ``binding'' of a variable
with a disequality. On the other hand, the
negation of an equation $X = t(\overline{Y})$ produces the universal
quantification of the free variables in the equation, unless a more
external quantification affects them. The negation of such an equation
is $\forall~ \overline{Y}~X \neq t(\overline{Y})$.
% He borrado la referencia a Carlsson
As we explained in \cite{SusanaPADL2000}, the inclusion of
disequalities and constrained answers has a very low cost. It
incorporates negative normal form constraints instead of bindings and
the decomposition step can produce disjunctions. More precisely, the
normal form of constraints is:

%\vspace{-20pt}
\[ \underbrace{\bigwedge_i (X_i = t_i)}_{\mbox{positive information}} \wedge~~~~ (
\underbrace{\bigwedge_j \forall~ \overline{Z}_j^1~(Y_j^1 \neq s_j^1)
\vee \ldots \vee \bigwedge_l \forall~ \overline{Z_l}^n~(Y_l^n
\neq s_l^n) )}_{\mbox{negative information}} \]
%\vspace{-20pt}

\noindent
where each $X_i$ appears only in $X_i = t_i$, none $s_k^r$ is $Y_k^r$
and the universal quantification could be
empty (leaving a simple disequality).

Using some normalization rules we can obtain a normal form
formula from any initial formula. It is easy to redefine
the unification algorithm to manage constrained variables.

This very compact way to represent a normal form was firstly presented in
\cite{Moreno1} and differs from Chan's representation where
only disjunctions are used\footnote{Chan treats the disjunctions
by means of backtracking. The main advantage of our normal form is
that the search space is drastically reduced.}.

Therefore, in order to include disequalities into a Prolog compiler we
need to reprogram unification. It is possible if the Prolog version
allows attributed variables \cite{Carlsson} (e.g. in Sicstus Prolog,
or in Eclipse where they are called meta-structures). These variables
let us keep associated information with each variable during the
unification what can be used to dynamically control the constraints.

Attributed variables are variables with an associated attribute, which
is a term. We will associate to each variable a data structure
containing a normal form constraint. Basically, a list of list of
pairs (variable, term) is used. They behave like ordinary variables,
except that the programmer can supply code for unification, printing
facilities and memory management.  In our case, the printing facility
is used to show constrained answers. The main task is to provide a new
unification code.

Once the unification of a variable $X$ with a term $t$ is
triggered, there are three possible cases (up to
commutativity):

%\vspace{-5pt}
\begin{enumerate}
%\addtolength{\itemsep}{-8pt}
\item if $X$ is a free variable and $t$ is not a variable with a negative
constraint, $X$ is just bound to $t$,
\item if $X$ is a free variable or bound to a term $t'$ and
$t$ is a variable $Y$ with a negative constraint, we need to check
if $X$ (or, equivalently, $t'$) satisfies the constraint associated with $Y$.
A conveniently defined predicate {\tt satisfy} is used for this purpose,
\item if $X$ is bound to a term $t'$ and $t$ is a term (or a variable
bound to a term), the classical unification algorithm can be used.
\end{enumerate}
%\vspace{-5pt}

We have defined a predicate {\tt =/= /2} \cite{SusanaPADL2000}, used
to check disequalities, in a similar way to explicit unification ({\tt
  =}). Each constraint is a disjunction of conjunctions of
disequalities that are implemented as a list of lists of terms as
$T_1/T_2$ (that represents the disequality $T_1 \neq T_2$). When a
universal quantification is used in a disequality (e.g., $\forall Y~ X
\neq c(Y)$) the new constructor {\tt fA}$/1$ is used (e.g., {\tt X /
  c(fA(Y)))}.

The first list is used to represent disjunctions while
the inside list represents the conjunction of disequalities.
We focus on the variable $X$.

%\hspace{-0.5cm}
\begin{center}
\begin{small}
\begin{tabular}{lll}
SUBGOAL & ATTRIBUTE & CONSTRAINT \\
\hline\hline
\ \\
{\tt not\_member (X,[1,2,3])}   &  $[[X/1,X/2,X/3]]$  & $X \neq 1 \wedge X \neq 2 \wedge X \neq 3$\\
{\tt member (X,[1,2,3]), X=/=2} &  $[[X/1,X/3]]$       & $X \neq 1 \wedge X \neq 3$\\
{\tt member (X,[1]), X=/=1}     &  {\tt fail}          & $false$ \\
{\tt X =/= 4}                   & $[[X/4]]$            & $X \neq 4$ \\
{\tt X =/= 4; X=/=5}            & $[[X/4], [X/5]]$     & $X \neq 4 \vee X \neq 5$ \\
{\tt X =/= 5; (X=/=6, X=/=Y)}   & $[[X/4],[X/6, X/Y]]$ & $X \neq 4 \vee (X \neq 6 \wedge X \neq Y)$\\
{\tt forall (Y, X =/= s (Y)) )}     & $[[X/s(fA(Y)]]$  & $\forall Y. X \neq Y$ \\
%{\tt (member (X,[0,s(0),s(s(0))]),} &                  & \\
%{\tt forall (Y, X =/= s (Y)) )}     & $0$              & $X = 0$
\end{tabular}
\end{small}
\end{center}



%%%%%%%% OPTIMIZATION  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Optimization}
\label{optimization}

\noindent
{\bf Compact information}. We have decided to represent negative
information in a compact way providing lesser solutions from the
negation of $\overline{I}$. The advantage is that if we ask
for all solutions using backtracking we are cutting the search tree by
offering all the solutions together in one only answer. For example we can
offer a simple answer for
%OJO - Juanjo: No hay codigo para p. 
% Lo dejo pero me parece qu no contribuye en nada
\begin{verbatim}
?- cneg(p(X,Y,Z,W)).

[[X/0, Y/s(Z)], [X/Y], [X/Z], [X/W], [X/s(0)], [Z/0]] ? ;
no
\end{verbatim}

\noindent
(that is equivalent to $ (X \neq0 \wedge Y\neq s(Z)) \vee X \neq Y
\vee X \neq Z \vee X \neq W \vee X \neq s(0) \vee Z \neq 0$)
instead of returning six answers:
\begin{verbatim}
?- cneg(p(X,Y,Z,W)).

[X/0, Y/s(Z)] ? ;
[X/Y] ? ;
[X/Z] ? ;
[X/W] ? ;
[X/s(0)] ? ;
[Z/0] ? ;
no
\end{verbatim}


\noindent
{\bf Pruning subgoals}. We have cut the search tree of the generation
of the frontiers with a double action over the ground subgoals:
removing soon the subgoals whose failure we are able to detect, and
simplifying the subgoals that we can reduce to true. Suppose we have a
predicate $p/2$ defined as
\begin{verbatim}
p(X,Y):- greater(X,Y),
         q(X,Y,Z),
         r(Z).
\end{verbatim}
We can imagine that $q/3$ and $r/1$ are predicates defined by several
clauses with a complicated implementation. If we would like to obtain
the frontier of $p(s(0),s(s(0)))$ to negate this goal, we would get:

$$Frontier(p(s(0),s(s(0)))) \equiv $$
$${ X=s(0) \wedge Y=s(s(0)) \wedge
  greater(X,Y) \wedge q(X,Y,Z) \wedge r(Z) } \equiv $$
$${ greater(s(0),s(s(0)) \wedge q(s(0),s(s(0),Z) \wedge r(Z) } \equiv $$
$${ fail  \wedge q(s(0),s(s(0),Z) \wedge r(Z) } \equiv $$
$$fail $$

Now we would have to expand the code of the subgoals of the frontier
to all the combination (disjunction) of the code of their clauses and
the result will be a very complicated and long to check frontier.
However we optimize the process evaluating the ground terms. In this
case $greater(s(0),s(s(0))$ fails and therefore it is no necessary to
continue with the generation of the frontier because the result is
reduced to fail (i.e. the negation of $p (s(0), s(s(0)))$ will be trivially
true). The opposite example means a simplification:

$$Frontier(p(s(s(0)),s(0))) \equiv $$
$${ X=s(s(0)) \wedge Y=s(0) \wedge greater(X,Y) \wedge q(X,Y,Z) \wedge
  r(Z) } \equiv $$
$${ greater(s(s(0)),s(0) \wedge q(s(s(0)),s(0),Z) \wedge r(Z) } \equiv
$$
$${ true \wedge q(s(s(0)),s(0),Z) \wedge r(Z) } \equiv $$
$${ q(s(s(0)),s(0),Z) \wedge r(Z) } $$

\noindent
{\bf Constraint simplification}. Another way of optimization is the
simplification of the constraints.  During all the process of negating
a goal the variables of the frontier are constrained. Sometimes the
constraints are satisfiable and we can eliminate them, other times
the constraints can be reduced to fail and we can stop the evaluation
of the negation because the result is true.
 
We intend to reduce a constraint $F$ to success or failure.
Constraints that are managed are formulas of the form:
\[ F \equiv  \bigvee_i\bigwedge_j \forall~ \overline{Z}_j^i~(Y_j^i \neq s_j^i) \]
We are going to transform this formula. Firstly we will obtained the
Prenex form \cite{Shoenfield} extracting the universal variables with
different names to the head of the formula applying logic rules:
\[ F \equiv \forall \overline{x} \bigvee_i\bigwedge_j (Y_j^i \neq s_j^i) \]
Using the distributive property:
\[ F \equiv \forall \overline{x} \bigwedge_k\bigvee_l (Y_l^k \neq s_l^k) \]
The formula can be separated into subformulas that are simple
disjunctions of disequalities :
\[ F \equiv \bigwedge_k \forall \overline{x} \bigvee_l (Y_l^k \neq s_l^k) \equiv F_1 \wedge ... \wedge F_n\]
Now we have to evaluate each single formula $F_k$. The first step will
be to substitute the existential quantified variables (those that do
not belong to $\overline{x}$) by Skolem constants $s^i_j$ that will keep the
equivalence without loosing generality:
\[ F_k \equiv \forall \overline{x} \bigvee_l ( Y_l^k \neq s_l^k ) \equiv \forall \overline{x} \bigvee_l ( Y_{Sk l}^k \neq s_{Sk l}^k )  \]
Then we transform it into:
\[ F_k \equiv  \neg \exists ~ \overline{x} \neg ( \bigvee_l (Y_{Sk l}^k \neq s_{Sk l}^k) ) \equiv \neg Fe_K \]
The meaning of $F_k$ is the negation of the meaning of $Fe_k$. Then
the next goal is evaluating $Fe_k$:
\[ Fe_k \equiv \exists ~ \overline{x} \neg ( \bigvee_l (Y_{Sk l}^k \neq s_{Sk l}^k)) \] 
Resolving the negations we obtain the result through simple unifications of the variables of $\overline{x}$:

\[ Fe_k  \equiv \exists ~ \overline{x} \bigwedge \neg (Y_{Sk l}^k \neq s_{Sk l}^k)  \equiv \exists ~ \overline{x} \bigwedge (Y_{Sk l}^k = s_{Sk l}^k)  \]
        Therefore we get the truth value of the $F_k$ from the
        negation of the value of $Fe_k$ and finally the value of $F$ is
        the conjunction of the values of all the $F_k$. If $F$
        succeeds then we remove the constraint because is redundant
        and we continue with the negation process. If it fails then
        the negation directly succeeds.

%%%%%%%% EXAMPLES  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Examples}
\label{examples}

The interesting side of this implementation is that it returns
constructive results from a negative question. Let us start with a
simple example involving predicate $boole/1$.

\begin{minipage}{2in}
\begin{verbatim}
boole(0).
boole(1).
\end{verbatim}
\end{minipage}
\begin{minipage}{2in}
%\rnode{A}{}
\begin{verbatim} 

    ?- cneg(boole(X)).
    [[X/1,X/0]] ? ;
    no
\end{verbatim} 
%\rnode{B}{}
%\ncline{A}{B}
\end{minipage}\\

Other simple example obtained from \cite{Stuckey95} gives us the
following answers:

\begin{minipage}{2in}
\begin{verbatim}
p(a,b,c).
p(b,a,c).
p(c,a,b).

proof1(X,Y,Z):-
    X =/= a,
    Z = c,
    cneg(p(X,Y,Z)).
\end{verbatim}
\end{minipage}
\begin{minipage}{2in}
\begin{verbatim} 

   ?- proof1(X,Y,Z).

   Z = c,
   [[X/b,X/a]] ? ;

   Z = c,
   [[Y/a,X/a]])) ? ;

   no
\end{verbatim} 
\end{minipage}\\

Other example inspired on another one from \cite{Stuckey95} show us
how a constructive answer ($\forall T ~ X \neq s(T)$) is provided from
an undefined goal in Prolog:

\begin{minipage}{2in}
\begin{verbatim}

p(X):- X = s(T), q(T).

q(T):- q(T).

r(X):- cneg(p(X)).
\end{verbatim}
\end{minipage}
\begin{minipage}{2in}
\begin{verbatim} 
   ?- r(X).

   [[X/s(fA(_A))]]

\end{verbatim} 
\end{minipage}\\



More interesting examples are those that have an infinite number of
solutions.

\begin{minipage}{2in}
\begin{verbatim}
positive(0). 
positive(s(X)):-
        positive(X).  
\end{verbatim}
\end{minipage}
\begin{minipage}{2in}
%\rnode{A}{}
\begin{verbatim} 

    ?- cneg(positive(X)).

    [[X/s(fA(_A)),X/0]] ? ;
    X = s(_A),
    [[_A/s(fA(_B)),_A/0]] ? ;
    X = s(s(_A)),
    [[_A/s(fA(_B)),_A/0]] ? ;
    X = s(s(s(_A))),
    [[_A/s(fA(_B)),_A/0]] ? 
    yes
\end{verbatim} 
%\rnode{B}{}
%\ncline{A}{B}
\end{minipage}

\begin{minipage}{2in}
\begin{verbatim}
number(0).
number(s(X)):-
        number(X).

greater(s(X),0):-
        number(X).
greater(s(X),s(Y)):-
        greater(X,Y).
\end{verbatim}
\end{minipage}
\begin{minipage}{2in}
%\rnode{A}{}
\begin{verbatim} 
    ?- cneg(greater(X,Y)).

    [[Y/0,Y/s(fA(_A))]] ? ;

    [[Y/s(fA(_A))]],
    [[X/s(fA(_B))]] ? ;

    X = s(_A),
    Y = 0,
    [[_A/s(fA(_B)),_A/0]] ? ;

    X = s(s(_A)),
    Y = 0,
    [[_A/s(fA(_B)),_A/0]] ? ;

    X = s(s(s(_A))),
    Y = 0,
    [[_A/s(fA(_B)),_A/0]] ? ;

    X = s(s(s(s(_A)))),
    Y = 0,
    [[_A/s(fA(_B)),_A/0]] ? 

    yes
\end{verbatim} 
%\rnode{B}{}
%\ncline{A}{B}
\end{minipage}


%%%%%%%%%%%%%%%%%%%%%%%% RESULTS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Experimental results}
\label{results}

We have firstly measured the execution times in milliseconds for the
previous examples when using negation as failure ($naf/1$) and
constructive negation ($cneg/1$). A `-' in a cell means that the
negation as failure is not applicable. All measurements were made
using \ciao\ Prolog\footnote{The negation system is coded as a library
  module (``package'' \cite{ciao-modules-cl2000}), which includes the
  corresponding syntactic and semantic extensions (i.e. Ciao's
  attributed variables). Such extensions apply locally within each
  module which uses this negation library.} 1.5 on a Pentium II at 350
Mhz. The results are shown in Table~\ref{table}. We have added a first
column with the runtime of the evaluation of the goal that is negated
in the other columns and a last column with the ratio that measures the
speedup of the \naf\ technique w.r.t. the constructive negation.

Using {\bf naf} instead of {\bf cneg} results in slight speed-ups near
1.06 in average for ground calls with few recursive calls. So the
possible slow-down from the constructive negation is not so high as we
could expect for these examples. Furthermore the results are rather
similar. But the same goals with data that involves many recursive
calls give us speed-ups near 14.69 in average and increasing
exponentially with the number of recursive calls. Additionally, there
are, of course, many goals that cannot be negated using the \naf\
technique and that are resolved using constructive negation. 

\input{table} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%% CONCLUSIONS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{-1em}
\section{Conclusion and Future Work}
\label{conclusion}
\vspace{-1em}
After making some preliminary experiments with the constructive 
negation technique  following Chan's description, we realized that the
algorithm needed some additional explanations and modifications.

Once we have specified the algorithm in a detailed way we proceed to provide
a real, complete and consistent implementation. The result we have reported are
very encouraging because we have proved that it is possible to extend
Prolog with a constructive negation module in a relatively cheap way.
However, the algorithm is inherently inefficient, so it is quite 
important to take care of possible optimizations and we are working 
to improve the efficiency of the implementation. Among them we can mention
a more accurate selection of the frontier based on the demanded form
of argument in the vein of \cite{Moreno2}). Another future work is
to incorporate our algorithm into the WAM machine level.

In any case we will probably not be able to provide a efficient enough
implementation of constructive negation. That is the reason why we do
not intend to use it neither for all cases of negation nor for
negating goals directly.

Our goal is to design and implement a practical negation operator and
incorporate it into a Prolog compiler.
In~\cite{SusanaPADL2000,SusanaLPAR01} we studied systematically what
we understood to be the most interesting existing proposals: negation
as failure (\naf) \cite{Clark}, use of delays to apply \naf\ in a
secure way~\cite{naish:lncs}, intensional
negation~\cite{Barbuti1,Barbuti2}, and constructive negation
\cite{Chan1,Chan2,Drabent,Stuckey,Stuckey95}. As none of them can
satisfy our requirements of completeness and efficiency, we proposed
to use a combination of these techniques and the information from a
static analysis of the program could be used to reduce the cost of
selecting among techniques \cite{SusanaLPAR01}. So we avoid the
inefficiency of the constructive negation. However we still need it because
is the only one that is sound and complete for
any kind of goals. For example, if we observe the goals of
Table~\ref{table} the strategy will obtain all ground negation using
the \naf\ technique and only would use constructive negation for the
goals with variables where it is impossible to use \naf\ . 

We are testing the implementation trying to improve the code and our
intention is to include it in the next distribution of Ciao Prolog
\footnote{http://www.clip.dia.fi.upm.es/Software}.
  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% BIBLIOGRAPHY %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

 \begin{small}

% \linespread{0.80}
    \bibliographystyle{plain} 
    \bibliography{bibliography}

 \end{small}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}

$\neg p(\overline{X})$ 
$\overline{\texttt{X}}$
$\overline{\texttt{X}}$
$t_1 \neq t_2$
$X \neq t$
${\cal H}$
$X \neq b \vee Y \neq a$
$X = t(\overline{Y})$ 
$\forall~ \overline{Y}~X \neq t(\overline{Y})$
\[ \underbrace{\bigwedge_i (X_i = t_i)}_{\mbox{positive information}} \wedge  \]
\[ \underbrace{\bigvee_j \forall~ \overline{Z}_j^1~(Y_j^1 \neq s_j^1)
\wedge \ldots \wedge \bigvee_l \forall~ \overline{Z_l}^n~(Y_l^n
\neq s_l^n)}_{\mbox{negative information}} \]
$X_i$ 
$X_i = t_i$
$s_k^r$
$Y_k^r$
$t'$ 
$\forall Y~ X \neq c(Y)$
$ Q \equiv S_1 \vee S_2 \vee ... \vee S_n $
$ S_i \equiv S_i^1 \wedge S_i^2 \wedge \ldots \wedge S_i^{m_i} $
$\neg Q \equiv$
   $\neg (S_1 \vee S_2 \vee \ldots \vee S_n)$  $\equiv$ \\
   $\neg S_1 \wedge \neg S_2 \wedge \ldots \wedge \neg S_n$  $\equiv$ \\
   $\neg (S_1^1 \wedge \ldots \wedge S_1^{m_1}) \wedge  \ldots$  \\
   $   \ldots\wedge
    \neg (S_n^1 \wedge \ldots \wedge S_n^{m_n})$  $\equiv$ \\
   $(\neg S_1^1 \vee \ldots \vee \neg S_1^{m_1}) \wedge  \ldots$ \\
   $ \ldots \wedge
    (\neg S_n^1 \vee \ldots \vee \neg S_n^{m_n})$  \\

$S_i^j$
$\forall~ X,Y,Z ~ p(X,Y,Z)$
$S_1 = [(Sk(1),Sk(2),Sk(3))]$ \\
$S_2 = [\underline{(0,Sk(1),Sk(2))}, \underline{(s(Sk(1)),Sk(2),Sk(3))}]$ \\
$S_3 = [\underline{(0,0,Sk(1))}, \underline{(0,s(Sk(1)),Sk(2))},
        (s(Sk(1)),Sk(2),Sk(3))]$ \\
$S_4 = [\underline{(0,0,0)}, \underline{(0,0,s(Sk(1)))},
        (0,s(Sk(1)),Sk(2)),(s(Sk(1)),$ \\
~~~~~~~~$        (s(Sk(1)),Sk(2),Sk(3))]$ \\
$S_5 = [(0,0,0), \underline{(0,0,s(0))}, \underline{(0,0,s(s(Sk(1))))},
        (0,s(Sk(1)),Sk(2)),$ \\
~~~~~~~~$        (s(Sk(1)),Sk(2),Sk(3))]$\\
$S_6 = \ldots$
$P(\overline{\texttt{X}})$
\texttt{call\_not($G(\overline{X})$, S)}
\noindent

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%  THE END  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

